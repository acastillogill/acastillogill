---
title: "An objective measure"
subtitle: "What are objective measurements of when something is good and something is bad."
author: √Ångela Castillo-Gill
date: '2018-11-20'
slug: an-objective-measure
categories:
  - Journal
tags: 
  - Learning
draft: FALSE
summary: 
output:
 blogdown::html_page:
  fig_caption: true
editor_options: 
  chunk_output_type: console
---

# Goal's for today's session are:

1. Evaluate the `RMSE` and `MSE` in the base and improved tree. 

## Goal 1: Evaluate the `RMSE` and `MSE` in the base and improved tree. 

```{r read data, echo=FALSE, message=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)

opts_chunk$set(echo = FALSE,
               warning = FALSE,
               error = FALSE,
               message = FALSE,
               collapse= TRUE,
               comment = NA,
               tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file="/Volumes/TOSHIBAEXT/google_drive/acastillogill/content/homes.rds")
```

Right. So we know from previous posts that we pick the smallest tree within one standard error of the lowest `xerror`. Eggsellent. BUT. What can we use to objectively measure the difference between trees? We can use the error between a less pruned tree and the improved one. 


There are two measurements of error, the `rmse` and the `mae`.

The root mean square error (RMSE) or root mean standard deviation (RMSD) is defined as: 

$$RMSD =\sqrt {\frac {\sum _{i=1}^{n}({\hat {y}}_{i}-y_{i})^{2}}{n}}$$
Where $n$ is the sample size, and $\hat{y}_{i}$ are the predicted values for the dependent variable $y_{i}$. 

Without reading the definition, this looks like it it "punishing" the differences between the estimated values and actual values, then dividing it per observation and taking the square root so the units are the actual ones for the response variable. 

The other *performance metric*, which is the actual name for these tree-measuring-metrics, is called the `MAE`. Which I think stands for the mean absolute error is defined as:

$$MAE ={\frac {\sum _{i=1}^{n}\left|y_{i}-\hat {y_i}\right|}{n}}$$
It seems like the difference here is that the `RMSE` punishes differences while the `MAE` doesn't emphasise large differences as much. 

Now let's calculate these performance metrics for the original tree and then the pruned tree. 

```{r }
#Splitting data
# Randomly assign rows to ids (1/2/3 represents train/valid/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/valid/test split will be approximately 70% / 15% / 15% 
set.seed(1)
assignment <- sample(1:3, size = nrow(homes),
                     prob = c(0.7,0.15,0.15),
                     replace = TRUE)

# Create a train, validation and tests from the original data frame 
homes_train <- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_valid <- homes[assignment == 2, ]  # subset the homes data frame to validation indices only
homes_test <- homes[assignment == 3, ]   # subset the homes data frame to test indices only
```

```{r basic-model, fig.cap="A first model suggests 9 splits with 10 nodes."}
# Train the model
homes_model <- rpart(formula = SalePrice ~ ., 
                     data = homes_train, 
                     method = "anova")

# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
```


```{r tuning-hyperparameters, include=FALSE}
# Plot the "CP Table"
plotcp(homes_model)

# Print the "CP Table"
print(homes_model$cptable)
```

```{r}
#Computing predicted values on the test set (NOT the training test)
pred_base <- predict(object=homes_model,
                newdata = homes_test)

library(Metrics)
rmse_base <- rmse(actual=homes_test$SalePrice, #Actual values
     predicted = pred_base )
mae_base <- mae(actual=homes_test$SalePrice, #Actual values
     predicted = pred_base )
```

The `rmse` for the base model `homes_model` is `r  rmse_base` and the `mae` is `r mae_base`. 

```{r improved-model, fig.cap="Improved model has 7 splits and 8 nodes."}
# Retrieve optimal cp value based on cross-validated error
opt_index <- 7
cp_opt <- homes_model$cptable[opt_index, "CP"]

# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model, 
                         cp = cp_opt)
                          
# Plot the optimized model
 rpart.plot(x = homes_model_opt, type = 5, extra = 1)
```

```{r}
#Computing predicted values 
pred_opt <- predict(object=homes_model_opt,
                newdata = homes_test)

#Compute RMSE
rmse_opt <- rmse(actual=homes_test$SalePrice, #Actual values
     predicted = pred_opt) #Predicted values

#Compute MAE
mae_opt <- mae(actual=homes_test$SalePrice, #Actual values
    predicted = pred_opt) #Predicted values
```

 
The `rmse` for the improved model `homes_model_opt` is `r  rmse_opt` and the `mae` is `r mae_opt`.

Ugh oh. It has gone up. Something is wrong. Why? 