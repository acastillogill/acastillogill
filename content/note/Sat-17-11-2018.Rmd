---
title: "The basics"
subtitle: "I need to properly understand the difference between a few things."
author: √Ångela Castillo-Gill
date: '2018-11-17'
slug: the-basics
categories:
  - Journal
tags: 
  - Learning
draft: FALSE
summary: 
output:
 blogdown::html_page:
  fig_caption: true
editor_options: 
  chunk_output_type: console
---

# Goal's for today's session are:

1. Go over the difference between standard deviation, variance, and standard error.

2. Evaluate the `RMSE` and `MSE` in the base and improved tree. 

## Goal 1: Go over the difference between standard deviation, variance, and standard error.

So in a few machine learning algorithms, if not all of them, there are three terms that are contantly being used with "mean" and "median": Standard deviation, variance, and standard error. I have probably studied these three terms and written their formulas too many times to mention here and you know what? If you asked me right now to explain the difference with every day examples, I don't think I could. Over time they have become a mush and I realise the reason they don't stick is because they are something I haven't associated with something that makes sense to me. 

So today I will define these world-renowned measures of dispersion today and try to come up with examples from my every day life.

* Sample variance: 

$$s^2 = \frac{1}{N-1} \sum_{i=1}^N (x_i - \overline{x})^2$$
Where, $N$ is the sample size; $x_i$ is the observation or piece of data, and $\overline{x}$ is the data set mean.

The differences between each point and the mean are squared to avoid negative differences cancelling positive ones. The variance units are the mean units squared. 

**Example**: Today I went for my grocery shop so let's work from there. Let's say I add lemons (1.68), apples (1.9), grapes (1.4), bananas (.97), and pine nuts (5.4) to my receipt. 

Then I ask, I wonder what the average price of each ingredient was, so I add and divide to create a simple average. 

```{r echo=TRUE, message=TRUE }
grocery_bill<- c(1.68,1.9,1.4,0.97,5.4)
sum(grocery_bill)/length(grocery_bill)
```

2.27, fabulous. Now, I want to see how much variation there is amongst each ingredient.

```{r}
grocery_bill-mean(grocery_bill)
```

It seems like the last two items, bananas and pine nuts varied quite a bit more from the mean. Let's add the differences now because let's say I want to show my husband how bigger the difference is when we add pine nuts. 

```{r}
sum(grocery_bill-mean(grocery_bill))
```

They have cancelled out. I think this is what you do when you want the regression line to go through the origin.

In order to take each difference without it cancelling out, we SQUARE. AHA. Ok. I think maybe this will help it stick.

```{r}
sum((grocery_bill-mean(grocery_bill))^2)
```

Great, now we divide by the 5 items.

```{r}
(sum((grocery_bill-mean(grocery_bill))^2))/5
var(grocery_bill)
```

Then I also computed the variance with base R and they were different. Why? Because I forgot the $N-1$ bit. Classic.

```{r}
(sum((grocery_bill-mean(grocery_bill))^2))/4
var(grocery_bill)
```

Now they are the same. But why do we substract $-1$. It seems the answer is because we want to have an unbiased estimator and it's called the *Bessel's correction* (?????). 

* Sample standard deviation: 

$$s = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (x_i -\overline{x})^2}$$

Now, the sample standard deviation is just the square root of the variance. It has the same units as the mean. On our groceries:

```{r}
sqrt((sum((grocery_bill-mean(grocery_bill))^2))/4)
sd(grocery_bill)
```

It is the same! Ok. Well done. So 1.78 Euros is how much each item of my grocery list on average deviates from the mean which was `r mean(grocery_bill)`. 

* Standard error: 

$$\sigma_{\bar {x}}\ \approx {\frac {s}{\sqrt {n}}}$$
So from what I can see it's the sample standard deviation divided by the square root of the sample size. mmmm, but why?

According to Wikipedia: *The standard error (SE) of a statistic (usually an estimate of a parameter) is the standard deviation of its sampling distribution...*
mmmmm ok. 

*or an estimate of that standard deviation.*

Looking at the formula, this latter definition makes more sense. 

*If the parameter or the statistic is the mean, it is called the standard error of the mean (SEM).*

But actually, not. I don't really get this, yet. 

Then it reads: *It can also be understood as the standard deviation of the error in the sample mean with respect to the true mean (or an estimate of that statistic).*

I think I'm going to let this one sink for today because I gotta run.

You know what, this was extremely basic but a helpful reminder I should do more often. Would be fun to compare the standard deviation between my grocery shop and my husband's. I need a refresher like this with the median and distribution skewness. 
```{r read data, echo=FALSE, message=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)

opts_chunk$set(echo = FALSE,
               warning = FALSE,
               error = FALSE,
               message = FALSE,
               collapse= TRUE,
               comment = NA,
               tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file="/Volumes/TOSHIBAEXT/google_drive/acastillogill/content/homes.rds")
```

```{r }
#Splitting data
# Randomly assign rows to ids (1/2/3 represents train/valid/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/valid/test split will be approximately 70% / 15% / 15% 
set.seed(1)
assignment <- sample(1:3, size = nrow(homes),
                     prob = c(0.7,0.15,0.15),
                     replace = TRUE)

# Create a train, validation and tests from the original data frame 
homes_train <- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_valid <- homes[assignment == 2, ]  # subset the homes data frame to validation indices only
homes_test <- homes[assignment == 3, ]   # subset the homes data frame to test indices only
```

```{r basic-model, fig.cap="A first model suggests 9 splits with 10 nodes.", include=FALSE}
# Train the model
homes_model <- rpart(formula = SalePrice ~ ., 
                     data = homes_train, 
                     method = "anova")

# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
```


```{r tuning-hyperparameters, include=FALSE}
# Plot the "CP Table"
plotcp(homes_model)

# Print the "CP Table"
print(homes_model$cptable)
```



```{r improved-model, fig.cap="Improved model has 7 splits and 8 nodes.", include=FALSE}
# Retrieve optimal cp value based on cross-validated error
opt_index <- 7
cp_opt <- homes_model$cptable[opt_index, "CP"]

# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model, 
                         cp = cp_opt)
                          
# Plot the optimized model
 rpart.plot(x = homes_model_opt, type = 5, extra = 1)
```

 
