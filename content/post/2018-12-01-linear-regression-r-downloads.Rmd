---
title: "Linear regression: who tends to download R software"
author: √Ångela Castillo-Gill
date: '2018-12-01'
slug: linear-regression-r-downloads
categories: []
tags: 
  - Kaggle
  - Tidy Tuesday
  - EDA
  - Maps
description: "To define."
banner: "banners/edu_index_downloads_capita.png"
images: ["banners/edu_index_downloads_capita.png"]
draft: TRUE
summary: ""
header: 
  image: "banners/edu_index_downloads_capita.png"
  caption: ""
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 2
  fig_caption: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
x <-
  c("dplyr",
    "knitr",
    "here",
    "scales",
    "magrittr",
    "ggplot2",
    "cowplot",
    "tidyverse",
    "Metrics",
    "rsample",
    "broom",
    "sf",
    "rgdal",
    "summarytools",
    "tmap",
    "tmaptools",
    "lubridate",
    "RColorBrewer",
     "hrbrthemes",
    "ggrepel")


lapply(x, require, character.only = TRUE)


opts_chunk$set(echo = FALSE,
               warning = FALSE,
               error = FALSE,
               message = FALSE,
               collapse = TRUE,
               comment = NA,
               tidy = TRUE,
               include = FALSE)

theme_set(theme_ipsum_rc())

options(
  digits=4,
  scipen = 999
)


knit_hooks$set(inline = function(x) {
  prettyNum(round(x,4), big.mark=",")
})


r_downloads <- readRDS(file=here::here("static","data","r-downloads.rds"))

r_downloads <- na.omit(r_downloads)%>%
  filter(date<"2018-10-20")

```

# Summary

*To see the code used in this post, visit my [kernel on kaggle in R Markdown format](https://www.kaggle.com/adcastillogill/r-downloads-around-the-world/code).* 



# Question



# Dataset description 

I used the [Tidy Tuesday dataset](https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-10-30) for R downloads posted on 30th October 2018. 

The dataset contained 938,115 observations and eight features corresponding to a unique id, download date, time, size, version, os, country, and IP id. The downloads correspond to a year's worth of downloads running from 2017-10-20 to 2018-10-20. To prevent any overlap and have one entire year, I limited downloads until 2018-10-19. After I removed missing values, there were `r nrow(r_downloads)` observations.

```{r read-data}
iso_codes <- read_csv(here::here("static","data","iso_countries.csv"))

pop <-read_csv(here::here("static","data","country_populations.csv"))

map_path <- here::here("static","data","world_shapefile","world_shapefile.shp")
world <- sf::st_read(map_path)

educ <- read_csv(here::here("static","data","edu_year.csv"))

educ$edu_index <- as.double(educ$edu_index)

```

```{r merge-country-codes}
r_downloads%<>%
  full_join(iso_codes, by=c("country"="iso"))%>%
  filter(!is.na(sub_region))
```

```{r downloads-by-country}
r_downloads%>%
  group_by(name)%>%
  summarise(n=n())%>%
  filter(!is.na(n))%>%
  arrange(desc(n))->downloads_per_country
```


In a [previous post]() I had a look at the which countries downloaded R the most. That let me to ask which countries were the most intense R users, using downloads per capita as a proxy. 

When I was writing the conclusions on which countries were the most intense users, I tried to draw up patterns. What the countries had in common was that they were "developed" countries. Does developed mean high levels of education and that's why they end up being intensive R users.

To further explore the relationship between countries that intense R users and education, I decided to do some regression analysis.

# The relationship between the education index and R downloads

```{r create-tibble-with-pop-and-users-only}
full_maps <- downloads_per_country%>%
  full_join(iso_codes, by=c("name"="name"))%>%
  filter(!is.na(sub_region))%>%
  left_join(pop, by=c("name"="name"))%>%
  select(n, name, iso_3, region, sub_region, pop_2018)%>%
  mutate(n_capita=n/pop_2018)%>%
  filter(!is.na(n_capita),
         pop_2018!=0)
```


```{r merge-years-of-education}

full_maps_edu <- full_maps%>%
  left_join(educ, by="name")%>%
  mutate(edu_index_percent=edu_index*100)%>%
  na.omit()

```


```{r plot-relationship-between-educ-and-n-capita,include=TRUE, fig.height=7,fig.cap="There appears to be an exponential relationship between the education index and the number of R downloads per capita."}
ggplot(full_maps_edu, aes(x=edu_index_percent, y=n_capita))+
  geom_point(alpha=0.5)+
  labs(title="The education index vs. R downloads per capita",
       x="Education index",
       y="R downloads per capita")+
  geom_text_repel(aes(label=name), force=0.2, size=2, segment.alpha = 0.5)
```

We're seeing some sort of exponential behaviour in the y-axis. Why don't we try the same plot but logging the dependent variable. 

```{r plot-relationship-between-educ-and-n-capita-log,include=TRUE, fig.cap="By taking the logarithm of R downloads per capita, we have met the criteria for a linear regression."}
ggplot(full_maps_edu, aes(x=edu_index_percent, y=log(n_capita)))+
  geom_point(alpha=0.5)+
  geom_smooth(method="lm", color="salmon", se=FALSE, size=2, alpha=0.5)+
  geom_text_repel(aes(label=name), force=0.2, size=2, segment.alpha = 0.5)+
  labs(title="The Education Index vs. R Downloads per Capita",
       x="Education index",
       y="R downloads per capita (logarithm applied)")
```

The relationship between the two variables is linear now - time for a linear regression!


```{r create-model-of-educ-r-capita}
fit <- lm( log(n_capita) ~ edu_index_percent, data = full_maps_edu)
summary(fit)
plot(fit)
```

After checking out the residuals, we can see there are a few outliers, mainly observations Turkmenistan, Tajikistan, Libya, Burkina Faso, and Chad. I'm going to leave them in, anyway because it's interesting to think about what specific characteristcs contributes to them being be under or over the trend line.

This model explains `r summary(fit)$adj.r.squared*100` of the variation in the data. It's not a lot but it's also not insignificant. After having tried with other variables such as GDP and life expectancy, I found the education index to best predictor. 

```{r remove-outliers}
outliers <- c(160,148,140,95,162)

full_maps_edu_sans_outliers <- full_maps_edu[-outliers,]

fit_2 <- lm( log(n_capita) ~ edu_index_percent, data = full_maps_edu_sans_outliers)
summary(fit_2)
plot(fit_2)
```

Now I want to see if their is an increase in the model's adjusted R squared if we run a model for each region. 

```{r nesting-models}

full_maps_edu%>%
  group_by(region)%>%
  
  #Nest models
  nest()%>%

#Create linear regression

  mutate(model=map(data,~lm(formula=log(n_capita) ~ edu_index, data=.x)))%>%
  

#Metrics of all models
  
  mutate(coef=map(model,~glance(.x)))%>%
  
#Models  
  unnest(coef)%>%
  
  select(region, adj.r.squared)%>%
  kable()

```

I thought the model's adjusted R squared would go up but it didn't! Interesting. Let's look at the plot by regions. 


```{r plot-relationship-between-educ-and-n-capita-log-regions,include=TRUE, fig.cap="Seems that the relationship is less strong when the data is separated into regions."}
ggplot(full_maps_edu, aes(x=edu_index, y=log(n_capita)))+
  geom_point(alpha=0.5)+
  geom_smooth(method="lm", color="salmon", se=FALSE, size=2, alpha=0.5)+
  labs(title="The education index vs. R downloads per capita by region",
       x="Education index",
       y="R downloads per capita (logarithm applied)")+
  facet_wrap(.~region, scales="free")
```

The trend lines are less steep and also, by breaking up the data into smaller groups, we have less data points per group which make the results of the regression more unreliable.

# Results

- As we saw earlier, the education index explains `r  summary(fit)$adj.r.squared*100` in the variation of R Downloads around the world. 

- The geometric mean of R downloads per capita is `r exp(summary(fit)$coef[1])`.

- A one unit increase in the education index is expected to increase R downloads per capita by a factor of `r exp(summary(fit)$coef[2])`.




# Conclusion

```{r}
fit%>%
  augment()%>%
  select(log.n_capita., edu_index, .fitted)%>%
  View()
```

