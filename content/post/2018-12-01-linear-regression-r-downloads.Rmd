---
title: "Linear regression: who tends to download R software"
author: √Ångela Castillo-Gill
date: '2018-12-01'
slug: linear-regression-r-downloads
categories: []
tags: 
  - Kaggle
  - Tidy Tuesday
  - EDA
  - Maps
description: ""
banner: "banners/r-downloads.png"
images: ["banners/r-downloads.png"]
draft: TRUE
summary: ""
header: 
  image: "banners/r-downloads.png"
  caption: ""
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 2
  fig_caption: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
x <-
  c("dplyr",
    "knitr",
    "here",
    "scales",
    "magrittr",
    "ggplot2",
    "cowplot",
    "tidyverse",
    "Metrics",
    "rsample",
    "broom",
    "sf",
    "rgdal",
    "summarytools",
    "tmap",
    "tmaptools",
    "lubridate",
    "RColorBrewer",
     "hrbrthemes")


lapply(x, require, character.only = TRUE)


opts_chunk$set(echo = FALSE,
               warning = FALSE,
               error = FALSE,
               message = FALSE,
               collapse = TRUE,
               comment = NA,
               tidy = TRUE,
               include = FALSE)

theme_set(theme_light())

options(
  digits=3,
  scipen = 999
)


knit_hooks$set(inline = function(x) {
  prettyNum(round(x,2), big.mark=",")
})


r_downloads <- readRDS(file=here::here("static","data","r-downloads.rds"))

r_downloads <- na.omit(r_downloads)%>%
  filter(date<"2018-10-20")

```

# Summary

*To see the code used in this post, visit my [kernel on kaggle in R Markdown format](https://www.kaggle.com/adcastillogill/r-downloads-around-the-world/code).* 



# Question



# Dataset description 

I used the [Tidy Tuesday dataset](https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-10-30) for R downloads posted on 30th October 2018. 

The dataset contained 938,115 observations and eight features corresponding to a unique id, download date, time, size, version, os, country, and IP id. The downloads correspond to a year's worth of downloads running from 2017-10-20 to 2018-10-20. To prevent any overlap and have one entire year, I limited downloads until 2018-10-19. After I removed missing values, there were `r nrow(r_downloads)` observations.

```{r read-data}
iso_codes <- read_csv(here::here("static","data","iso_countries.csv"))

pop <-read_csv(here::here("static","data","country_populations.csv"))

map_path <- here::here("static","data","world_shapefile","world_shapefile.shp")
world <- sf::st_read(map_path)

educ <- read_csv(here::here("static","data","edu_year.csv"))

educ$edu_index <- as.double(educ$edu_index)

```

```{r merge-country-codes}
r_downloads%<>%
  full_join(iso_codes, by=c("country"="iso"))%>%
  filter(!is.na(sub_region))
```

```{r downloads-by-country}
r_downloads%>%
  group_by(name)%>%
  summarise(n=n())%>%
  filter(!is.na(n))%>%
  arrange(desc(n))->downloads_per_country
```


In a [previous post]() I had a look at the which countries downloaded R the most. That let me to ask which countries were the most intense R users, using downloads per capita as a proxy. 

When I was writing the conclusions on which countries were the most intense users, I tried to draw up patterns. What the countries had in common was that they were "developed" countries. Does developed mean high levels of education and that's why they end up being intensive R users.

To further explore the relationship between countries that intense R users and education, I decided to do some regression analysis.

# The relationship between the education index and R downloads

```{r merge-years-of-education}

full_maps_edu <- full_maps%>%
  left_join(educ, by="name")%>%
  na.omit()

```


```{r plot-relationship-between-educ-and-n-capita,include=TRUE, fig.cap="There appears to be an exponential relationship between the education index and the number of R downloads per capita."}
educ_vs_n_capita_plot <- ggplot(full_maps_edu, aes(x=edu_index, y=n_capita))+
  geom_point(alpha=0.5)+
  labs(title="The education index vs. R downloads per capita",
       x_lab="Education index",
       ylab="R downloads per capita")
```



```{r create-model-of-educ-r-capita}
fit <- lm( log(n_capita) ~ edu_index, data = full_maps_edu)
summary(fit)
par(mfrow=c(2,2))
plot(fit)
```


# Conclusion

