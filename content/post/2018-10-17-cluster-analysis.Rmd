---
title: "Clustering: cereals, supermarket shelves, and sugar"
author: √Ångela Castillo-Gill
date: '2018-10-17'
slug: cluster-analysis-cereals
categories: []
tags: 
  - Cluster analysis
  - Hierarchical clustering
description: "I do perform two types of clustering on the Kaggle cereals dataset."
banner: "banners/cluster.png"
images: ["banners/cluster.png"]
draft: FALSE
header: 
  image: "banners/cluster.png"
  caption: ""
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 2
  fig_caption: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
x <-
  c("dplyr",
    "knitr",
    "here",
    "scales",
    "magrittr",
    "ggplot2",
    "cowplot",
    "tidyverse",
    "Metrics",
    "rsample",
    "broom",
    "sf",
    "rgdal",
    "summarytools",
    "tmap",
    "tmaptools",
    "lubridate",
    "RColorBrewer",
    "hrbrthemes",
    "ggrepel",
    "dummies",
    "stats",
    "ggrepel",
    "kableExtra",
    "dendextend",
    "cluster",
    "tidylog")


lapply(x, require, character.only = TRUE)


opts_chunk$set(echo = FALSE,
               warning = FALSE,
               error = FALSE,
               message = FALSE,
               collapse = TRUE,
               comment = NA,
               tidy = TRUE,
               include = FALSE,
               fig.height=10, 
               fig.width=14)

theme_set(theme_ipsum_rc())

options(
  digits=4,
  scipen = 999
)




cereals <- read_csv(here::here("static","data","cereals.csv"))
```

# Summary

*To see the all the code used in this post, visit my [GitHub repository for this site](https://github.com/acastillogill/acastillogill)* 

- Objectives: To find what what kind of clusters are there in the [cereals dataset](https://www.kaggle.com/crawford/80-cereals/home) available on Kaggle. 
- Challenge: To implement a clustering algorithm for the first time.
- Data points: `r length(cereals)*nrow(cereals)`
- Language: R 


# Question

**What types of clusters are there in the cereals dataset?**

# Dataset description 

The dataset is available on Kaggle. It contains nutrition data on 80 cereal products. I chose this dataset because it had plenty of numeric variables and I'm interested in using two types of clustering algorithms to explore the data. Another reason I chose this dataset is because the data is unlabelled so I can add labels with clustering. 

I wanted to focus on numeric variables using Euclidean distances. Not all variables in the dataset were numeric: the cereal name, the manufacturer, the type of cereal (hot or cold). There was also a numeric variable `Shelf` corresponding to the supemarket display shelf that doesn't make much sense as a numeric variable, so I removed it from the analysis. After leaving just numeric variables, I was left with 12 variables. 

I first scaled the data because I will calculate the Euclidean distance between each cereal but the variables are on different scales. When the data are scaled, the mean for each variable will be zero and a standard deviation of one.

```{r scaling-data}
#Remove categorical variables
num_cereals <- cereals[,4:16]
#Remove shelf
num_cereals$shelf <- NULL
#scale numeric variables
num_cereals <- scale(num_cereals)
#Calculate distances
dist_cereals <- dist(num_cereals, method = "euclidean")
```


# Hierarchical clustering


I first implemented hierarchical clustering with three different linkage methods. Generally, the hierarchical clustering algorithm works by first linking the two observations that are closest together. It then chooses the closest observation based on **a distance** between the current observation and its distance to each element in a pair. That distance may vary according to the type of linkage as I show in the next tree diagrams (or dendrograms).


```{r hierarchical-clustering-complete}

#Hierarchical clustering by complete linkage
hc_cereals_complete <- hclust(dist_cereals, method = "complete")

#Selecting two clusters
clusters_k2_complete <- cutree(hc_cereals_complete, k=2)

#Appending the clusters to all the dataset
cereals_k2_complete <- mutate(cereals, cluster=clusters_k2_complete)

complete_count <- count(cereals_k2_complete, cluster)
complete_count
```

```{r hierarchical-clustering-single}

#Hierarchical clustering by single linkage
hc_cereals_single <- hclust(dist_cereals, method = "single")

#Selecting two clusters
clusters_k2_single <- cutree(hc_cereals_single, k=2)

#Appending the clusters to all the dataset
cereals_k2_single <- mutate(cereals, cluster=clusters_k2_single)

single_count <- count(cereals_k2_single, cluster)
```

```{r hierarchical-clustering-average}

#Hierarchical clustering by average linkage
hc_cereals_average <- hclust(dist_cereals, method = "average")

#Selecting two clusters
clusters_k2_average <- cutree(hc_cereals_average, k=2)

#Appending the clusters to all the dataset
cereals_k2_average <- mutate(cereals, cluster=clusters_k2_average)

average_count <- count(cereals_k2_average, cluster)
```


```{r plot-complete-linkage, include=TRUE, fig.cap="This tree diagram shows the complete linkage process. Here the algorithm chooses the closest MAXIMUM distance between the considered observation and the current pair. The height in the plot shows the distance between two observation. Each horizontal line represents the number of clusters. After choosing two clusters, we can say that maximum distance between observations in the two clusters is equal two or less than 11.06."}

dend_cereals_comp <- as.dendrogram(hc_cereals_complete)
dend_colored_comp <- color_branches(dend_cereals_comp, k=2)
plot(dend_colored_comp)
```


```{r plot-average-linkage, include=TRUE, fig.cap="This is the average linkage with maximum height 7.57. Here the algorithm chooses the closest AVERAGE distance between the considered observation and the current pair. Although the maximum distance between obsverations in a cluster is shorter than in complete linkage, average linkage leads to one cluster with three observations and another with 74. This an unbalanced set of clusters."}

dend_cereals_av <- as.dendrogram(hc_cereals_average)
dend_colored_av <- color_branches(dend_cereals_av, k=2)
plot(dend_colored_av)

```


```{r plot-single-linkage, include=TRUE, fig.cap="Single linkage has even a smaller distance between observations with the maximum being 4.16. Here the algorithm chooses the closest MINIMUM distance between the considered observation and the current pair. Here 76 observations are in one cluster and one is in another. "}
dend_cereals_sin <- as.dendrogram(hc_cereals_single)
dend_colored_sin <- color_branches(dend_cereals_sin, k=2)
plot(dend_colored_sin)
```

I wanted balanced clusters so I ended up choosing the complete linkage method that classified observations more or less into two similar groups with one cluster having 30 observations and the other 47. Now I'd like to show the differences amongst clusters for each numerical variable. 

```{r mean-for-each-cluster, include=TRUE}
two_clusters <- cereals_k2_complete %>% 
  select(-shelf,-name,-mfr,-type,-cups,-weight)%>%
  group_by(cluster) %>% 
  summarise_all(funs(mean(.)))%>%
  cbind(complete_count$n)
  
  kable(two_clusters, caption="Cluster two on average has 20% more calores, 35% less protein, 70% more sodium, 60% less fiber, more than twice as much sugar, 40% less potasium, 86% more vitamins and 37% lower ratings.")%>%
  kable_styling()
```


```{r table-counting-sugar-shelf, include=TRUE}

shelf_cluster <- table(cereals_k2_complete$shelf,cereals_k2_complete$cluster)

colnames(shelf_cluster) <- c("Cluster 1","    Cluster 2")

shelf_cluster%>%
  kable(row.names = TRUE, caption="The top shelf (3), has roughly an equal quantity of cereals belonging to either cluster. The bottom shelf (1) only has two cereals difference. The  middle shelf, however, has three times as much cluster two")%>%
  kable_styling()
```


```{r plot-sugar-shelf, include=TRUE}

 ggplot(cereals_k2_complete, aes(x = sugars, y = shelf, color = factor(cluster))) +
  geom_point(alpha=0.5)+
  scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
  geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
    scale_y_continuous(breaks=c(1,2,3))+
  labs(title="Which shelf has the most sugary cereals?",
       x="Sugar content per serving",
       y="Supermarket shelf: from the floor (1) to the top (3)")
  

```


```{r plot-sodium-shelf, include=TRUE}

 ggplot(cereals_k2_complete, aes(x = sodium, y = shelf, color = factor(cluster))) +
  geom_point(alpha=0.5)+
  scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
  geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
    scale_y_continuous(breaks=c(1,2,3))+
  labs(title="Which shelf has the most sodium-rich cereals?",
       x="Sodium content per serving",
       y="Supermarket shelf: from the floor (1) to the top (3)")
  

```



# Results

# Conclusion


