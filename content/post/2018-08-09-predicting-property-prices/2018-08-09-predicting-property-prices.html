---
title: Predicting property prices
author: Ángela Castillo-Gill
date: '2018-08-09'
slug: predicting-property-prices
categories:
  - R
  - RPART
tags: 
  - Kaggle
  - Home sales prices
draft: FALSE
summary: What factors most affect sales prices for homes?
header: 
  image: ""
  caption: "Test"
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 2
  fig_caption: true
editor_options: 
  chunk_output_type: console
---


<div id="TOC">
<ul>
<li><a href="#summary"><span class="toc-section-number">1</span> Summary</a></li>
<li><a href="#question"><span class="toc-section-number">2</span> Question</a></li>
<li><a href="#dataset-description"><span class="toc-section-number">3</span> Dataset description</a><ul>
<li><a href="#missing-values"><span class="toc-section-number">3.1</span> Missing values</a></li>
<li><a href="#correlation"><span class="toc-section-number">3.2</span> Correlation</a></li>
</ul></li>
<li><a href="#regression-trees---why-use-them"><span class="toc-section-number">4</span> Regression trees - why use them?</a><ul>
<li><a href="#variable-importance"><span class="toc-section-number">4.1</span> Variable importance</a></li>
</ul></li>
<li><a href="#results"><span class="toc-section-number">5</span> Results</a></li>
<li><a href="#what-does-it-mean"><span class="toc-section-number">6</span> What does it mean?</a></li>
</ul>
</div>

<div id="summary" class="section level1">
<h1><span class="header-section-number">1</span> Summary</h1>
<p><em>To see the code used in this post, visit my <a href="https://www.kaggle.com/adcastillogill/exploring-kiva-loans">kernel on kaggle in R Markdown format</a>.</em></p>
</div>
<div id="question" class="section level1">
<h1><span class="header-section-number">2</span> Question</h1>
<p>Let’s say that you have a house in Ames, Iowa (that’s where the dataset is from). You’re about to buy a house or even buy some terrain and you want to understand <strong>what makes a house more valuable than others</strong>.</p>
</div>
<div id="dataset-description" class="section level1">
<h1><span class="header-section-number">3</span> Dataset description</h1>
<p>The dataset <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">House Prices: Advanced Regression Techniques</a> was put together by <a href="https://ww2.amstat.org/publications/jse/v19n3/decock.pdf">Dean De Cock.</a> It has 79 explanatory variables describing 1,460 homes in Ames, Iowa. The codebook for all the variables can be <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">found here.</a> As I go along, I’ll explain the most relevant ones. The dataset has 38 numeric and 43 character variables. Next, since we are interested in estimating <code>SalePrice</code>, we will see the most strongly correlated variables. There are 43 character variables available.</p>
<div id="missing-values" class="section level2">
<h2><span class="header-section-number">3.1</span> Missing values</h2>
<p>As is more common than not, the dataset contains missing values. Missing values need to be dealt with because often regression (and other models) require complete observations. Dealing with missing data depends on <em>why the data are missing</em>. <a href="http://www.stat.columbia.edu/~gelman/arm/missing.pdf">This article</a> explains four reasons why data could be missing. When the data are missing at random (MAR) or completely at random (MCAR), observations with missing values can be removed without introducing bias into the model. Sometimes, however, if the dataset is not too big and we don’t want to lose observations, or even if it is big, yet we still don’t want to remove observations, we can impute data. Imputing means replacing missing values by doing some educated guesses. <a href="https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4">This article</a> summarises how to impute data depending on why it is missing. If the data are not missing at random, then the imputation mechanism has to modelled.</p>
<p>About 19 variables have missing values. Based on the codebook, the reason why so many houses have <code>PoolQC</code> missing is because <code>NA</code>, means there is no pool. Since this variable is ordinal, I can revalue it to make it numerical and <code>0</code> will mean the property has no pool. <code>MiscFeature</code>, <code>Alley</code>, <code>Fence</code>, and <code>FireplaceQu</code> are missing because of similar reasons. We don’t know why <code>LotFrontage</code> is missing but we will impute as the median for properties in the same neighborhood. I learned a lot about imputation and missing values from <a href="https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda/code">Erik Bruin’s kernel on Kaggle</a>.</p>
</div>
<div id="correlation" class="section level2">
<h2><span class="header-section-number">3.2</span> Correlation</h2>
<p>Correlation, <span class="math inline">\(Cor(X,Y)\)</span>, measures the strength of the linear relationship between two variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The correlation between <code>SalePrice</code> and another variable, let’s say, <code>OverallQual</code>, is the covariance of the separately normalised data between the two variables.</p>
<pre class="r"><code>cov(scale(homes$SalePrice), scale(homes$OverallQual))
      [,1]
[1,] 0.791</code></pre>
<p>Since covariance units are <code>OverallQual</code> * <code>SalePrice</code>, calculating the correlation is more helpful since as is unit free. If we created a model with only one variable as the predictor of <code>SalesPrice</code>, let’s say, <code>KitchenQual</code> and normalised the data, the regression slope would be the correlation between the two variables.</p>
<pre class="r"><code>norm_fit &lt;- lm(scale(SalePrice) ~ scale(KitchenQual), data = homes)
round(coefficients(norm_fit), digits = 2)
       (Intercept) scale(KitchenQual) 
              0.00               0.66 </code></pre>
<p>Now I’ll look at all variables - here is the correlation matrix for variables that have a relationship stronger than 0.5 with <code>SalePrice</code>.</p>
<p><img src="/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/correlation-matrix-1.png" width="672" /></p>
<p>Variables are arranged in descending order according to the strength of the relationship with <code>SalePrice</code>. There are 17 variables that have a correlation stronger than 0.5. When variables are highly correlated amongst each other, it’s better to remove some of them. The correlation plot highlights some obvious pairs that are related with another, for example, <code>GarageArea</code> and <code>GarageCars</code>. Makes sense, a bigger garage can hold more cars. <code>X1stFlrSF</code> and <code>TotalBsmtSF</code>, the total area of the first floor and basement, this also seems reasonable since basements are underneath the same floor and would tend to have a similar area. <code>TotRmsAbvGrd</code> and <code>GrLivArea</code>, the total number of rooms and area above ground, again ok, more rooms would be linked to a bigger living area. Finally, <code>YearsSinceBuilt</code> and <code>YearsSinceGarageBuilt</code> since garages are usually built at the same time as the house.</p>
</div>
</div>
<div id="regression-trees---why-use-them" class="section level1">
<h1><span class="header-section-number">4</span> Regression trees - why use them?</h1>
<p>The tool that I’m going to be using to solve is regression trees. It’s also known as as classification and regression trees (CART) or the recursing and partitioning (RPART) algorithm. The reason I’m choosing this tool or algorithm to answer the business question is because regression trees are interpretable and we can make easy-to- follow plots with them. It will be implemented with the <code>rpart</code> package in R. Rpart, builds a model in two stages:</p>
<p><strong>First stage</strong>:</p>
<p>The variable which can best<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> split the data into two groups is identified. The data are then separated into two groups and the whole process is repeated <em>recursively</em> or indefinitely until the sub-groups reach a minimum size, or until no further improvements can be made. When the split is made, similarity amongst the observations can more or less homogenous. This homogeneity is also called purity and it can be measured. The impurity measure of a node specifies how mixed the resulting subset is.</p>
<p><strong>Second stage</strong>:</p>
<p>The tree is trimmed back or prunned using cross-validation. We identify the lowest cross-validated error or the smallest within one standard error of the tree with lowest cross-validated error.</p>
<div id="variable-importance" class="section level2">
<h2><span class="header-section-number">4.1</span> Variable importance</h2>
<p>Using the <code>rpart</code> function, we are able to rank which variables are most predictive of <code>SalePrice</code>. The following plot ranks these variables in descending order.</p>
<div class="figure"><span id="fig:variable-importance-table"></span>
<img src="/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/variable-importance-table-1.png" alt="Overall quality is the most predictive variable and the one that originally had the most correlation with `SalePrice`, it's followed by basement quality and Total basement square feet." width="672" />
<p class="caption">
Figure 4.1: Overall quality is the most predictive variable and the one that originally had the most correlation with <code>SalePrice</code>, it’s followed by basement quality and Total basement square feet.
</p>
</div>
</div>
</div>
<div id="results" class="section level1">
<h1><span class="header-section-number">5</span> Results</h1>
<div class="figure">
<img src="/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/final_plot-1.png" alt="The tree with 10 nodes and 9 splits had the least lowest performance metric `RMSE`." width="672" />
<p class="caption">
(#fig:final_plot)The tree with 10 nodes and 9 splits had the least lowest performance metric <code>RMSE</code>.
</p>
</div>
<p>The most influential variable for <code>SalePrice</code> was <code>OverallQual</code>. This variable “rates the overall material and finish of the house”, values equal or above to 8 correspond to “very good”, “excellent”, and “very excellent”. On one hand, houses with a rating of 8 or above in <code>OverallQual</code>, the next most decisive variable is <code>TotalBsmtSF</code>, which is the “total square feet of basement area”. If it’s above 1,850, the house is classified depending on <code>Neighborhood_type</code>. Fancy houses are thoses that are in either of these neighborhoods NridgHt, NoRidge, StoneBr. All other neighborhoods are not fancy. Houses below 1,850 feet are further classified depending on the <code>GarageArea</code>.</p>
<p>On the other hand, houses with a rating below 8 for <code>OverallQual</code>, the same variable decides again classifying them above or equal to 7, which is “good”. Either way, houses will be classified again by <code>GrLivArea</code>: “above grade living area in square feet”, where smaller houses will depend on basement size (<code>TotalBsmtSF</code>) or on <code>MS_type</code>, which describes the type of dwelling. Modern dwellings include: split foyer, 1-story built in 1946 or newer. Less modern dwellings are 1945 or older in some cases.</p>
<p>In response to the question: what makes a house more valuable than others? Many variables in the tree are related to area: basement, garage, and total living. Even the number of rooms to some extent depends on the size of the house. So an important one definitely is size. But more important than size in this case, the overall quality of the house is critical.</p>
</div>
<div id="what-does-it-mean" class="section level1">
<h1><span class="header-section-number">6</span> What does it mean?</h1>
<p>It seems that having in very good or better condition pays a lot. Would it be worth to find a house in a somewhat fancy neighborhood and work on improving its finish and materials. Who knows? That is a causal question. There is a strong relationship between <code>OverallQual</code> and <code>SalePrice</code> but correlation does not imply causation. As a final note it’s important to add that to a large extent the results of this analysis are limited Ames, Iowa, where this dataset is from.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The best tree is the smallest tree with highest cross-validated error.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
