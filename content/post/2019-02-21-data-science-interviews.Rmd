---
title: "Data science interviews: lessons learned"
author: Ángela Castillo-Gill
date: '2019-02-21'
slug: data-science-interviews
categories: []
tags: 
  - Reflection
  - Talk
  - R-Ladies London
description: "In this post I share how I spent my time during my data scientist job search. I then use this information to point out things I would have done differently and things I'm glad I did. The content of this blogpost was first presented at R-Ladies London on 2019-02-21."
banner: "banners/london.jpg"
images: ["banners/london.jpg"]
draft: FALSE
header: 
  image: "banners/london.jpg"
  caption: ""
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 2
  fig_caption: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
x <-
  c(
    "knitr",
    "here",
    "scales",
    "magrittr",
    "cowplot",
    "tidyverse",
    "Metrics",
    "rsample",
    "broom",
    "sf",
    "rgdal",
    "summarytools",
    "tmap",
    "tmaptools",
    "lubridate",
    "RColorBrewer",
     "hrbrthemes",
    "ggrepel")


lapply(x, require, character.only = TRUE)


opts_chunk$set(echo = FALSE,
               warning = FALSE,
               error = FALSE,
               message = FALSE,
               collapse = TRUE,
               comment = NA,
               tidy = TRUE,
               include = FALSE)

theme_set(theme_ipsum_rc())

job_search <- read_csv(file=here::here("static","data","job_search.csv"))


```


# Summary

In this post I share how I spent my time during my data scientist job search. I then use this information to point out things I would have done differently and things I'm glad I did. The content of this blogpost was first presented at R-Ladies London on 2019-02-21 and the presentation is [here](https://acastillogill.com/slides/2019-02-21-r-ladies-data-science-interviews-presentation.html#1): 

```{r include=TRUE}
knitr::include_url('https://acastillogill.com/slides/2019-02-21-r-ladies-data-science-interviews-presentation.html#1')
```

To summarise:

**Would have done differently:**

- Establish healthy boundaries with recruiters
- Focus on the basics for technical tests
- Schedule interviews at favourable times
- Practice not knowing and staying confident


**Glad I did:**

- Have a mentor to support you along the way
- Be transparent about other interviews

# Why?

I just finished a month-long data scientist job search in London. It was successful because it produced the data scientist role I'm about to start. I'm excited! Despite the success, there are things I could have done differently. My job search included international relocation, which did not make it easy. Also, during the third week I went to four job interviews in a row. This was not a good idea. Now that the dust has settled, I share these and other lessons with three objectives in mind: 

1. **Is there anybody out there?** I'd like to know if others have gone through a similar situation and if so, please leave a comment or write me an e-mail about your experience. It's important to hear how others overcame the obstacles I had to deal with and what obstacles have others faced.

2. **To guide/advice others:** Of course, this was my personal experience and I would take it with a grain of salt. After all, I'm just one observation and that's why we need a bigger sample size (see objective 1). However, I do hope this will be helpful to someone in their data scientist job search.


3. **For my future self:** Hopefully I won't have to go through a job search in a while but as a memento of what has happened, I'd like to leave these lessons for my future self.

# Here's how I spent my time

I track time spent working to update my learning loop and allocate time. I tried to extend this to my job search by tracking as many activities as possible. I now discuss the tasks I show in the plot.


```{r read-time}
job_search$date <- dmy(job_search$date)
job_search$task <- as.factor(job_search$task)
job_search <- job_search %>%
  select(date, amount, task) %>%
  filter (date>"2019-01-04")
```


```{r plotting-time-usage, include=TRUE, fig.width=10}
job_search%>%
  group_by(date, task)%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time usage during data scientist job search",
       x="Date",
       y="Time")+
  scale_fill_brewer(palette = "Paired")
```


## Adapting CVs

On the 5th January 2019 I met my mentor (more on this later). We went through my CV and my LinkedIn profile in detail. After, I dedicated a few hours to putting what she suggested into practice. This activity had a high return on investment. 

```{r plotting-adapting-CVs, include=TRUE, fig.width=10}
job_search%>%
  group_by(date, task)%>%
  filter(task=="Adapting CVs")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent adapting CVs",
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values="#A6CEE3" )+
  theme(legend.position = "none")
```


## Face-to-face interviews

This is one of my to-improve points. I scheduled four interviews in one week just two days after I moved countries with all my belongings. DO NOT DO THIS. I could have spaced out interviews as this was not necessary. This ended up having a negative impact on my performance at interviews, especially those scheduled later in the week.


```{r plotting-face-interviews, include=TRUE, fig.width=10}


job_search%>%
  group_by(date, task)%>%
  filter(task=="Face to face interviews")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent at face-to-face interviews",
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values =   "#1F78B4"   ) +
  theme(legend.position = "none")
```


## Filling out forms

This was a surprise. I thought I would have to fill out more job applications than I did. The time spent here was minimal because I ended up working mostly with recruiters. I wish I would have tracked it but most of my applications were through LinkedIn. I also had the intention to fill out my details on other job search platforms like Indeed, Monster, etc. but this ended up not being necessary. 

```{r plotting-filling-forms, include=TRUE, fig.width=10}


job_search%>%
  group_by(date, task)%>%
  filter(task=="Filling out forms")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent filling out forms",
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values =   "#B2DF8A"   ) +
  theme(legend.position = "none")
```


## Interview prep

This includes researching companies and preparing for technical tests, doing technical tests. Notice the peak on 17th January? That was me prettifying plots as part of a technical test `r emo::ji("nail_care")`

During my interview week I split the day between being at interviews and then cramming for the next. This was not fun and led to sub-optimal results.


```{r plotting-interview-prep, include=TRUE, fig.width=10}

job_search%>%
  group_by(date, task)%>%
  filter(task=="Interview prep")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent preparing for interviews",
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values =   "#33A02C"   ) +
  theme(legend.position = "none")
```



## Job admin

This is basically everything related to sending e-mails to arrange phone calls, or interviews, and towards the end, going over the final job offer, signing, sealing it and delivering it to my new employer.

```{r plotting-job-admin, include=TRUE, fig.width=10}

job_search%>%
  group_by(date, task)%>%
  filter(task=="Job admin")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent doing administrative activities",
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values =   "#FB9A99"  ) +
  theme(legend.position = "none")
```


## Phone calls

This is another point to improve. At the beginning I was taking way too many unexpected phone calls from recruiters. This was an inefficient use of both parties' time. After a bit I tried to push back by asking for job specs first and then scheduling calls. More on this later. Phone calls also included technical interviews but these were only about two hours of the total seven hours spent on phone calls.

```{r plotting-phone-calls, include=TRUE, fig.width=10}
phone_calls <- job_search%>%
  filter(task=="Phone calls")%>%
  summarise(phone_call= seconds_to_period(sum(amount)))

job_search%>%
  group_by(date, task)%>%
  filter(task=="Phone calls")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent on phone calls",
       subtitle=paste("Only about 2.5 hrs of the total ~7 hrs on was spent on phone interviews." ),
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values =  "#E31A1C"  ) +
  theme(legend.position = "none")
```



## Writing cover letters

Again, surprisingly low. Only wrote one cover letter and didn't hear back from that company. The data scientist job search works in mysterious ways. 

```{r plotting-cover-letters, include=TRUE, fig.width=10}

job_search%>%
  group_by(date, task)%>%
  filter(task=="Writing cover letters")%>%
  ggplot(aes(x=date, y=amount, fill=task))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90,hjust=1))+
  scale_x_date(breaks = "1 day")+
  labs(title ="Time spent writing cover letters",
       x="Date",
       y="Time")+
  expand_limits(x=as.Date(c("2019-01-05","2019-02-12")))+
  scale_fill_manual(values = "#FDBF6F" ) +
  theme(legend.position = "none")
```



# What would I have done differently?

Here's the fun bit where I tell you how I fell down and scratched my knee so you don't have to. 

## Establish healthy boundaries with recruiters

This was my first time working with recruiters. I wasn't sure about how much time and attention to allocate to working with them and/or how to do it. At the beginning I always picked up the phone. Most of the conversations didn't add much value and were more of an interruption and distraction. I wasted a lot of time and headspace taking random recruiter calls, as I was moving countries, I could have invested those resources elsewhere. 

**What would I do now?**

After a week of this, I set this workflow for myself. My first point of contact is either LinkedIn or e-mail. If someone reaches out with a fantastic opportunity that seems especially well suited for me, I will say, "sounds great, please send over the job spec first". I will then sit down and read the job spec. After, I will Google the company, find the employees on LinkedIn and pause. Then I will reflect on whether I want to go forward or not. If I don't feel excited, move on immediately. Politely reply: "Thank you, however, this is not a good fit for me at this time." If I do feel excited, then go ahead and schedule that call. Make sure that I pick up only at the time it was scheduled.

## Focus on the basics for technical test prep

There are statistics and programming basics that every data scientist should know. You would think that because they are basics you would never forget them. Not me. During the last few months I had focused on re-writing manuscripts based on analysis done in the summer. I enjoyed the Christmas/New Year break and was focused on moving countries. I hadn't touched some bread and butter activities in a few months nor did I think about refreshing basic data wrangling or stats 101. Instead, I was out to impress and googled advanced data science interview questions. This strategy was flawed. I failed some technical questions that were not hard, I was just out of practice. When I think about it, I was just asked one neural network question, the rest was basics.

**What would I do now?**

I would focus less on specific algorithm details and just throughly freshen up on stats 101, data cleaning and wrangling basics by heart including syntax in both R and SQL.

## Schedule interviews at favourable times

I realise I was somewhat nervous about having any time gaps in my CV. This led me to cram moving countries and going to job interviews. I was so excited about the search that I allowed interviews to be scheduled one after another just a few days after moving house. This wasn't necessary and of course had a negative impact on my job search. I couldn't devote my full attention to interview prep.
 
**What would I do now?**

I don't think leaving a one month time gap would have had any negative consequences. Instead it would have given me enough time to settle in to start ramping up the interviewing process. I would also try to schedule interviews with at least one day in between and in the morning, if possible. 

## Rehearse not knowing, or being wrong, and feeling embarrassed/nervous/uncomfortable and STILL speaking with confidence

I have a new found respect for politicians. When they announce a policy or a plan at a press conference, inevitably they will be asked something they do not know. They might even be corrected on something they just said. The ability to keep calm or appear calm is something they have practiced over and over. I had no idea how important this skill is to practice until I went through this round of interviews. 

Public speaking has a been a priority because I tend to speak too fast and I could benefit from adding more intonation to my presentations. With that feedback in mind, I took locution lessons and joined public speaking clubs. Generally, you improve on the skill you practice. I had practiced speaking in a safe, controlled environment using rehearsed responses. I therefore, improved on speaking in a safe, controlled environment using rehearsed responses. That is NOT the public speaking skill you will need for data science interviews. Here, you need to practice not knowing, being corrected, and STAYING CHILL. I did not practice this skill at all. I let a couple of questions or situations, which unsettled me, have an impact on the rest of my interview. Not ideal. 

**What would I do now?**

I like public speaking clubs like Toastmasters because they have made me aware of my impact on an audience. I can tell when people are zoning out and what I have done to cause that. It's helped me improve my pace, pauses and intonation. But what I think would be better practice in this context is joining a debate club. In a debate there is another team actively pushing against you and trying to undermine what you're saying. Constantly. If they're skilled, they might even attempt to provoke a reaction. That's what I need to practice. Can anyone recommend debate clubs in London?

# What would I do again?

## Have a mentor to support you along the way

Through R-Ladies I met Raquel Redó, a data scientist based in Barcelona. Although the timing wasn't right because I was moving, we made sure we met face to face at least twice. Raquel has been doing data science work for a while and is very enthusiastic about supporting other women in the field. Perfect! She herself has gone through the data science interview process and had very wise words to offer. 
I think what made our mentorship work was that I wrote down all her advice after our first meeting and went off and did it. I put as much of her advice I could into practice. When I had scheduled my final round interviews, we went over the companies and she gave me some advice on them too. Going through data science interviews can feel a bit lonely and it's easy to doubt yourself. Having a mentor helped me make my search feel legitimate to myself and kept me accountable. This was good to have. 

## Be transparent about other interviews to everyone

This is very important for several reasons. First, you can manage expectations and follow ups. Imagine interviewing a candidate, offering them a position and then for days not hearing back from them. Rude. Do you even want this person to join your team? It also helps you to have some leverage in terms of package negotiation. At their request I disclosed to the recruiters I was working with, what offers other companies had made and without sharing details, I'm glad I did this `r emo::ji("100")`!

# Conclusion

The data science job search is quite to different to others. In my experience, very little time was spent filling out forms or writing cover letters. It was more about thoroughly researching the company and articulating how you will help them while keeping your technical and social abilities current and fresh. There are always things to improve upon and by distilling the four lessons I've shared, I hope to correct them next time. I also hope to hear from others who have gone through a similar processes and learn about their trials and tribulations. There are some things I got right, after all, I'm very excited to start my data scientist job soon. This worked for me but will not necessarily work for you so take my experience with a grain of salt. Finally, enjoy the process! It was fun to go to so many offices, meet so many people, and interview my interviewers. I'd like to think we both enjoyed the process. Hope to hear from your experience in the comments or privately through e-mail.

