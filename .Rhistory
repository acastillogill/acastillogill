table(homes$CentralAir)
#Recode KitchenQual
homes$KitchenQual<-as.integer(plyr::revalue(homes$KitchenQual, ordinal_scale))
#Recode Functional
homes$Functional      <- as.factor(homes$Functional)
#Recode PavedDrive
homes$PavedDrive       <- as.factor(homes$PavedDrive)
#Recode SaleType
homes$SaleType        <- as.factor(homes$SaleType)
#Recode SaleCondition
homes$SaleCondition     <- as.factor(homes$SaleCondition)
# Chunk 6: create time variables
homes<-homes%>%
#Mutate to create `YearsSinceBuilt`, `YearsSinceGarageBuilt`, and `YearsSinceRemod`
#It will be the difference of the present year - YearBuilt
mutate(YearsSinceBuilt = year(Sys.Date())-YearBuilt,
#Same for YearsSinceRemod
YearsSinceRemod = year(Sys.Date())-YearRemodAdd,
#Same for GarageYrBlt
YearsSinceGarageBuilt = year(Sys.Date())-GarageYrBlt)%>%
#Remove old variables, correlated ones, and ID
dplyr::select(-GarageYrBlt,
-YearRemodAdd,
-YearBuilt,
-GarageCars,
-BsmtQual,
-TotRmsAbvGrd,
-Id)
# Chunk 7: understanding-neighborhood-var
homes%>%
group_by(Neighborhood)%>%
summarise(Median=median(SalePrice))%>%
arrange(desc(Median))%>%
ggplot(aes(x=reorder(Neighborhood, Median), y=Median))+
geom_col()+
labs(title="Neighborhoods vs. Average SalePrice",
x="Neighborhood")+
scale_y_continuous(labels = scales::dollar_format(suffix = "", prefix = "$")) + coord_flip()
# Chunk 8: binning_neighboorhood
fancy <- c("NridgHt","NoRidge","StoneBr")
modern <- c("20","60","70","80","85","120")
homes <- homes%>%
mutate(Neighborhood_type=ifelse(Neighborhood %in% fancy, "Fancy","Not_fancy"),
MS_type=ifelse(MSSubClass %in% modern, "Modern","Less_modern"))
homes <- homes%>%
dplyr::select(-Neighborhood,
-MSSubClass)
# Chunk 9: export the data set for posts
#Save RDS
saveRDS(homes, file=here("data", "homes.RDS"))
# Chunk 10: covariance-example
cov(scale(homes$SalePrice), scale(homes$OverallQual))
# Chunk 11: single-regression-normalised-data
norm_fit <- lm(scale(SalePrice) ~ scale(KitchenQual), data = homes)
round(coefficients(norm_fit), digits = 2)
# Chunk 12: correlation-matrix
homes_num <- homes%>%
select_if(is.numeric)
#Create tidy correlation matrix
cor_homes <- tidy(cor(homes_num))
#Arrange correlations with SalePrice in descending order
high_cor_names <- cor_homes%>%
arrange(desc(SalePrice))%>%
filter(abs(SalePrice)>0.5)%>%#Filter variables that have relationship >0.5
pull(.rownames)#Pull names of variables
#Filter entire correlation matrix for the variables
high_cor <- cor(homes_num)[high_cor_names,high_cor_names]
#Create correlation matrix
corrplot.mixed(high_cor, tl.col="black", tl.pos = "lt",cl.ratio=0.1,number.cex=.6, cl.cex = .6, tl.cex = 0.6)
# Chunk 13
homes <- homes%>%
mutate(SalePrice=SalePrice/1000)
# Chunk 14: split-data
# Randomly assign rows to ids (1/2) represents train/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/test split will be approximately 70% / 30%
set.seed(1)
assignment <- sample(1:2, size = nrow(homes),
prob = c(0.7,0.3),
replace = TRUE)
# Create a train, validation and tests from the original data frame
homes_train <- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_test <- homes[assignment == 2, ]   # subset the homes data frame to test indices only
# Chunk 15: train the model
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes_train,
method = "anova")
# Chunk 16: variable-importance-table
#Look at variable importance
var_importance <- tidy(homes_model$variable.importance)
total_importance <- sum(var_importance$x)
var_importance%>%
mutate(names=fct_reorder(names,x))%>%
head(15)%>%
ggplot(aes(names,x/total_importance,fill=names))+
geom_col()+
scale_y_continuous(labels = scales::percent_format())+
coord_flip()+
labs(title="Top 15 most important variables for predicting `SalePrice`",
y="",
x="")+
theme(legend.position = "none")
# Chunk 17: initial-prediction
#Computing predicted values
pred_base <- predict(object=homes_model,
newdata = homes_test)
#Compute RMSE
rmse(actual=homes_test$SalePrice, #Actual values
predicted = pred_base ) #Predicted values
#Compute MAE
mae(actual=homes_test$SalePrice, #Actual values
predicted = pred_base ) #Predicted values
# Chunk 18: tuning-hyperparameters
# Plot the "CP Table"
plotcp(homes_model)
# Print the "CP Table"
print(homes_model$cptable)
# Retrieve optimal cp value based on cross-validated error
opt_index <- 7
cp_opt <- homes_model$cptable[opt_index, "CP"]
# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model,
cp = cp_opt)
# Chunk 19: prediction
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes_test)
#Compute RMSE
rmse(actual=homes_test$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
#Compute MAE
mae(actual=homes_test$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
# Chunk 20: final-plot
par(mar=c(1,1,1,1))
# Plot the optimized model
rpart.plot(x = homes_model, type = 5, extra = 1, digits = 0)
here::here()
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
options(digits=4)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file=here("data","homes.rds"))
homes
blogdown::serve_site()
blogdown::serve_site()
homes <- readRDS(file=here::here("data","homes.rds"))
rm(list = ls())
homes <- readRDS(file=here::here("data","homes.rds"))
rm(list = ls())
blogdown::serve_site()
path <- here::here("static","data","train.csv")
path
path <- here::here("static","data","property_train.csv")
#Read `train.csv` as homes
homes <- read.csv(path, stringsAsFactors = FALSE)
install.packages("roxygen2")
roxygen2::roxygenise()
downloads <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-30/r_downloads_year.csv")
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
options(digits=4)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file=here::here("static","data","homes.rds"))
downloads <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-30/r_downloads_year.csv")
saveRDS(downloads, here("static","data","r-downloads.rds"))
library(here)
saveRDS(downloads, here("static","data","r-downloads.rds"))
head(downloads)
downloads%>%
count(country)
downloads%>%
count(country)%>%
arrange(desc(n))->downloads_per_country
head(downloads_per_country)
downloads_per_country%>%
head(20)
downloads_per_country%>%
head(20)%>%
ggplot(aes(country,n))+
geom_col()
downloads_per_country%>%
head(20)%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
library(here)
library(scales)
options(digits=4)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
downloads <- readRDS(file=here::here("static","data","r-downloads.rds"))
downloads%>%
count(country,sort = TRUE)%>%
arrange(desc(n))->downloads_per_country
downloads_per_country%>%
head(20)%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()
downloads_per_country%>%
head(20)%>%
mutate(country=fct_reorder(country,n))+
ggplot(aes(country,n))+
geom_col()+
coord_flip()
downloads_per_country%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
labs(title="Top 20 countries by R downloads",
x="Country",
y=scale_y_continuous(labels = scales(labels=comma_format())))
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
library(here)
library(scales)
options(digits=4)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
downloads <- readRDS(file=here::here("static","data","r-downloads.rds"))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
labs(title="Top 20 countries by R downloads",
x="Country",
y=scale_y_continuous(labels = scales(labels=comma_format())))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
labs(title="Top 20 countries by R downloads",
x="Country",
y=scale_y_continuous(labels = labels=comma_format()))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
labs(title="Top 20 countries by R downloads",
x="Country",
y=scale_y_continuous(labels=comma_format()))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
labs(title="Top 20 countries by R downloads",
x="Country",
y=scale_x_continuous(labels=comma_format()))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
labs(title="Top 20 countries by R downloads",
x="Country",
y=scale_y_continuous(labels=comma_format()))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")
ISOcodes::ISO_15924
ISOcodes::ISO_3166_1
ISOcodes::ISO_639_2
iso_codes <- read_csv(here("static","data","iso_countries.csv"))
head(iso_codes)
downloads_per_country%>%
right_join(iso_codes, by=c("country"="iso"))
nrow(iso_codes)
nrow(downloads_per_country)
library(magrittr)
downloads_per_country%<>%
right_join(iso_codes, by=c("country"="iso"))
head(downloads_per_country)
downloads%>%
count(country,sort = TRUE)%>%
arrange(desc(n))->downloads_per_country
iso_codes <- read_csv(here("static","data","iso_countries.csv"))
downloads_per_country%<>%
right_join(iso_codes, by=c("country"="iso"))
downloads_per_country%>%
filter(!is.na(country))%>%
head(20)%>%
mutate(country=fct_reorder(country,n))%>%
ggplot(aes(country,n))+
geom_col()+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")
str(downloads_per_country)
downloads_per_country%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n))+
geom_col()+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n))+
geom_col()+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")
blogdown::serve_site()
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n,fill=name))+
geom_col()+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n,fill=name))+
geom_col()+
expand_limits(y=0)+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")+
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n,fill=name))+
geom_col()+
expand_limits(y=0)+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")+
theme(legend.position = "none")
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n,fill=name))+
geom_col()+
expand_limits(y=0)+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")+
theme(legend.position = "none")
majors_processed %>%
mutate(Major_category=fct_reorder(Major_category,Median))%>%
ggplot(aes(Major_category,Median, fill=Major_category))+
geom_boxplot()+
scale_y_continuous(labels = dollar_format())+
coord_flip()+
expand_limits(y=0)+
theme(legend.position = "none")
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n,fill=name))+
geom_col()+
expand_limits(y=0)+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")+
theme(legend.position = "none")
# Chunk 1: setup
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
library(here)
library(scales)
library(magrittr)
options(digits=4)
options(scipen = 999)
opts_chunk$set(echo = TRUE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
downloads <- readRDS(file=here::here("static","data","r-downloads.rds"))
# Chunk 4: downloads-by-country
downloads%>%
count(country,sort = TRUE)%>%
arrange(desc(n))->downloads_per_country
# Chunk 5: read-country-codes
iso_codes <- read_csv(here("static","data","iso_countries.csv"))
# Chunk 6: merge-country-codes
downloads_per_country%<>%
right_join(iso_codes, by=c("country"="iso"))
# Chunk 7: top-20-countries-plot
downloads_per_country%>%
arrange(desc(n))%>%
filter(!is.na(name))%>%
head(20)%>%
mutate(name=fct_reorder(name,n))%>%
ggplot(aes(name,n,fill=name))+
geom_col()+
expand_limits(y=0)+
coord_flip()+
scale_y_continuous(labels=comma_format())+
labs(title="Top 20 countries by R downloads",
x="Country",
y="Downloads")+
theme(legend.position = "none")
