# Chunk 53: skim clean dataset
skim(idealista_clean)
# Chunk 54: initial fit model
#Create a model for all variables
fit <- lm(PRICE~ ., data = idealista_clean, na.action = "na.fail")
tidy(anova(fit))%>%
arrange(p.value)%>%
filter(p.value<0.05)%>%
dplyr::select(term, statistic, p.value)
# Chunk 56: read_models
#Read models
all_models <- readRDS("all_models")
nrow(all_models)
# Chunk 58: total costs summary
total_costs %>%
mutate(total_lower=gov_cost_present+lower_date+lower_canary,
total_upper=gov_cost_present+upper_date+upper_canary) -> total_costs
carbon_benefits%>%
mutate(total_lower=  carbon_lower_date+carbon_lower_canary,
total_upper=carbon_lower_canary+carbon_upper_canary) -> total_benefits
# Chunk 59: costs and benefits summary
cb_lower <- data.frame(time, total_costs$total_lower,total_benefits$total_lower)
names(cb_lower) <- c("time","costs","benefits")
cb_upper <- data.frame(time, total_costs$total_upper,total_benefits$total_lower)
names(cb_upper) <- c("time","costs","benefits")
cb_lower%>%
summarise(sum(costs),sum(benefits)) ->cb_total_lower
cb_upper%>%
summarise(sum(costs),sum(benefits))->cb_total_upper
# Chunk 60: cost benefits plotted
cb_lower %>%
mutate(costs=costs/1000)%>%
gather(key = "type",value="amount",2:3)%>%
ggplot(aes(x=time,
y=amount,
color=type))+
geom_area(aes(fill=type),
position = "dodge",
alpha=0.5,linetype="dashed",size=1 )+
theme_classic()+
scale_x_continuous(breaks = int_breaks)+
guides( color = FALSE,
fill = guide_legend(title = ""))+
scale_fill_manual(values=c("#00BA38","#F8766D"))+
scale_color_manual(values=c("#00BA38","#F8766D"))+
labs(
title = "Costs vs. benefits (lower bound)",
subtitle = "Costs were divided by 1,000 to allow benefits to appear in the plot.",
x = "Time",
y = "Euros")+
theme(legend.position = "top")-> cb_lower_plot
cb_upper %>%
mutate(costs=costs/1000)%>%
gather(key = "type",value="amount",2:3)%>%
ggplot(aes(x=time,
y=amount,
color=type))+
geom_area(aes(fill=type),
position = "dodge",
alpha=0.5,linetype="dashed",size=1 )+
theme_classic()+
scale_fill_manual(values=c("#00BA38","#F8766D"))+
scale_color_manual(values=c("#00BA38","#F8766D"))+
scale_x_continuous(breaks = int_breaks)+
guides( color = FALSE,
fill = guide_legend(title = ""))+
labs(
title = "Costs vs. benefits (upper bound)",
subtitle = "Costs were divided by 1,000 to allow benefits to appear in the plot.",
x = "Time",
y = "Euros"
)+theme(legend.position = "top",
text=element_text(size=10)) -> cb_upper_plot
cost_benefit_plot<- arrangeGrob(cb_lower_plot,cb_upper_plot, nrow=2)
ggsave("cost_benefit_plot.png",
cost_benefit_plot,
width = 8,
height= 8,
limitsize = FALSE,
bg="transparent")
# Chunk 61: NSB
nsb_low <- round(sum(carbon_benefits$total_lower)-sum(total_costs$total_lower),digits = 0)
nsb_ratio_low  <- round(sum(total_costs$total_lower)/sum(carbon_benefits$total_lower),digits=0)
nsb_high <- round(sum(carbon_benefits$total_upper)-sum(total_costs$total_upper),digits=0)
nsb_ratio_high <- round(sum(total_costs$total_upper)/sum(carbon_benefits$total_upper),digits=0)
# Chunk 62: stock table summary
Summary_Stock <- as.vector(c("Healthy","Infested","In treatment","Lost","Replanted","Total population"))
Stock <- as.vector(c("$S_t^H$","$S_t^I$","$S_t^{T}$","$S_t^L$","$S_t^R$","$S_t$"))
df_stock <- as_tibble(Stock,Summary_Stock)
colnames(df_stock) <- c("Stock")
kable(df_stock, caption = "\\label{tab:stocks}Palm tree stocks.", booktabs = T,escape = F) %>%
kable_styling(latex_options = c("hold_position"))
# Chunk 63: flows table summary
Summary_Flow <- as.vector(c("Replanted",
"Failed prevention",
"Untreated",
"Treated",
"Failed treatment",
"Successful treatment"))
Flow <- as.vector(c("$F_{t,t-1}^R$",
"$F_{t,t-1}^{FP}$",
"$F_{t,t-1}^{UTR}$",
"$F_{t,t-1}^{TR}$",
"$F_{t,t-1}^{FT}$",
"$F_{t,t-1}^{ST}$"
))
df_flow <- as_tibble(Flow,Summary_Flow)
colnames(df_flow) <- c("Flow")
kable(df_flow, caption = "\\label{tab:flows}Palm tree flows.", booktabs = T,escape = F) %>%
kable_styling(latex_options = c("hold_position"))
# Chunk 64: gencat cost tables
gencat%>%
set_names(c("Year","GENCAT cost","GENCAT cost present"))%>%
kable(
caption = "\\label{tab:gencat_table}GENCAT costs associated to RPW expenditure over time.",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))%>%
footnote(general= paste0("Total cost of the evaluated policies for all years is ",
round(sum(gencat$gov_cost_present),digits = 0),
"."," Source: GENCAT, 2018."),
footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 65: date_cost_low table
date_cost_low%>%
set_names(c("Year","Replanting","Inspection","Prevention","Treatment","Removal","Total"))%>%
kable(
caption = "\\label{tab:date_costs_low}Management costs (lower bound) for date palms over time.",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))%>%
footnote(general=paste("Total cost of all activities for all years is ",round(sum(date_cost_low$total),digits = 0),".",sep = ""),
footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 66: date_cost_high table
date_cost_high%>%
set_names(c("Year","Replanting","Inspection","Prevention","Treatment","Removal","Total"))%>%
kable(
caption = "\\label{tab:date_costs_high}Management costs (upper bound) for date palms over time.",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))%>%
footnote(general=paste("Total cost of all activities for all years is ",round(sum(date_cost_high$total),digits = 0),".",sep = ""),
footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 67: canary_cost_low table
canary_cost_low%>%
set_names(c("Year","Replanting","Inspection","Prevention","Treatment","Removal","Total"))%>%
kable(
caption = "\\label{tab:canary_costs_low}Management costs (lower bound) for canary palms over time.",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))%>%
footnote(general=paste("Total cost of all activities for all years is ",round(sum(canary_cost_low$total),digits = 0),".",sep = ""), footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 68: canary_costs_high
canary_cost_high%>%
set_names(c("Year","Replanting","Inspection","Prevention","Treatment","Removal","Total"))%>%
kable(
caption = "Management costs (upper bound) for canary palms over time.",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))%>%
footnote(general=paste("Total cost of all activities for all years is ",round(sum(canary_cost_high$total),digits = 0),".",sep = ""), footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 69: total_costs
total_costs%>%
set_names(c("Year","GENCAT","Date","Canary","Total","Date","Canary","Total"))%>%
kable(
caption = "Total costs for canary and date palms over time.",
booktabs = T,
escape = F,
linesep= "") %>%
kable_styling(latex_options = c("hold_position"))%>%
add_header_above(c("","","Lower"=3,"Higher"=3))%>%
footnote(general=paste("Total for lower bound is ",round(sum(total_costs$total_lower),digits=0),", total for higher bound is ",round(sum(total_costs$total_upper),digits=0),".",sep = ""), footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 70: carbon benefits table
carbon_benefits%>%
set_names(c("Year","Date","Canary","Total","Date","Canary","Total"))%>%
kable(
caption = "\\label{tab:carbon_costs}Carbon sequestration values over time.",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))%>%
add_header_above(c("","Lower"=3,"Higher"=3))%>%
footnote(general=
paste0("Combining the totals for all years for both species yields a lower bound of ",
round(sum(carbon_benefits$total_lower),digits=0)," and a higher bound of ",
round(sum(carbon_benefits$total_upper),digits=0),"."),
footnote_as_chunk = T, threeparttable = TRUE)
# Chunk 71
df_date%>%
dplyr::filter(run==4)%>%
dplyr::select(time,
sHeal,
sInf,
sTre,
Replanting,
Failed_prevention,
Untreated,
Treated,
Failed_treatment,
Successful_treatment,Total_population)
# Chunk 73
library(stargazer)
stargazer(lm_date, type="latex")
# Chunk 74
stargazer(stepAIC(object=lm_date, k =log(n)), type = "latex")
# Chunk 75: canary_palms_model
stepAIC(object=lm_canary, k =log(n))%>%
tidy()%>%
kable(
caption = "Canary palms model estimates",
booktabs = T,
escape = F,
linesep= ""
) %>%
kable_styling(latex_options = c("hold_position"))
blogdown::serve_site()
options("digits")
options(scipen)
options("scipen")
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes_train)
#Compute RMSE
rmse_opt <- rmse(actual=homes_train$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
# Chunk 1: read data
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
options(digits=2)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file="/Volumes/TOSHIBAEXT/google_drive/acastillogill/content/homes.rds")
# Chunk 2
#Splitting data
# Randomly assign rows to ids (1/2/3 represents train/valid/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/valid/test split will be approximately 70% / 15% / 15%
set.seed(1)
assignment <- sample(1:3, size = nrow(homes),
prob = c(0.7,0.15,0.15),
replace = TRUE)
# Create a train, validation and tests from the original data frame
homes_train <- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_valid <- homes[assignment == 2, ]  # subset the homes data frame to validation indices only
homes_test <- homes[assignment == 3, ]   # subset the homes data frame to test indices only
# Chunk 3: basic-model
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes_train,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
# Chunk 4: tuning-hyperparameters
# Plot the "CP Table"
plotcp(homes_model)
# Print the "CP Table"
print(homes_model$cptable)
# Chunk 5
#Computing predicted values on the test set (NOT the training test)
pred_base <- predict(object=homes_model,
newdata = homes_test)
library(Metrics)
rmse_base <- rmse(actual=homes_test$SalePrice, #Actual values
predicted = pred_base )
mae_base <- mae(actual=homes_test$SalePrice, #Actual values
predicted = pred_base )
# Chunk 6: improved-model
# Retrieve optimal cp value based on cross-validated error
opt_index <- 7
cp_opt <- homes_model$cptable[opt_index, "CP"]
# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model,
cp = cp_opt)
# Plot the optimized model
rpart.plot(x = homes_model_opt, type = 5, extra = 1)
# Chunk 7
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes_test)
#Compute RMSE
rmse_opt <- rmse(actual=homes_test$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
#Compute MAE
mae_opt <- mae(actual=homes_test$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
# Chunk 8
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes_train)
#Compute RMSE
rmse_opt <- rmse(actual=homes_train$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
predicted = pred_opt) #Predicted values
rmse_opt
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes_train)
#Compute RMSE
rmse_opt <- rmse(actual=homes_train$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
rmse_opt
rmse_base
reprex::(print(homes_model$cptable))
reprex::(homes_model$cptable)
reprex::reprex(print(homes_model$cptable))
print(homes_model$cptable)
# Chunk 1: read data
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
options(digits=2)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file="/Volumes/TOSHIBAEXT/google_drive/acastillogill/content/homes.rds")
# Chunk 2
#Splitting data
# Randomly assign rows to ids (1/2/3 represents train/valid/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/valid/test split will be approximately 70% / 15% / 15%
set.seed(1)
assignment <- sample(1:3, size = nrow(homes),
prob = c(0.7,0.15,0.15),
replace = TRUE)
# Create a train, validation and tests from the original data frame
homes_train <- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_valid <- homes[assignment == 2, ]  # subset the homes data frame to validation indices only
homes_test <- homes[assignment == 3, ]   # subset the homes data frame to test indices only
# Chunk 3: basic-model
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes_train,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
# Chunk 4: tuning-hyperparameters
# Plot the "CP Table"
plotcp(homes_model)
# Print the "CP Table"
print(homes_model$cptable)
# Chunk 5
#Computing predicted values on the test set (NOT the training test)
pred_base <- predict(object=homes_model,
newdata = homes_test)
library(Metrics)
rmse_base <- rmse(actual=homes_test$SalePrice, #Actual values
predicted = pred_base )
mae_base <- mae(actual=homes_test$SalePrice, #Actual values
predicted = pred_base )
# Chunk 6: improved-model
# Retrieve optimal cp value based on cross-validated error
opt_index <- 7
cp_opt <- homes_model$cptable[opt_index, "CP"]
# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model,
cp = cp_opt)
# Plot the optimized model
rpart.plot(x = homes_model_opt, type = 5, extra = 1)
# Chunk 7
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes_test)
#Compute RMSE
rmse_opt <- rmse(actual=homes_test$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
#Compute MAE
mae_opt <- mae(actual=homes_test$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
rmse_base
# Retrieve optimal cp value based on cross-validated error
opt_index <- 7
cp_opt <- homes_model$cptable[opt_index, "CP"]
# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model,
cp = cp_opt)
# Plot the optimized model
rpart.plot(x = homes_model_opt, type = 5, extra = 1)
rmse_opt
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
names(homes)
# Train the model
homes_model <- rpart(formula = SalePrice ~ -Id.,
data = homes,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
# Train the model
homes_model <- rpart(formula = SalePrice ~ -Id,
data = homes,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
options(digits=2)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file="/Volumes/TOSHIBAEXT/google_drive/acastillogill/content/homes.rds")
homes <- homes%>%
select(-Id)
# Train the model
homes_model <- rpart(formula = SalePrice ~ -Id,
data = homes,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
# Plot the "CP Table"
plotcp(homes_model)
# Print the "CP Table"
print(homes_model$cptable)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(knitr)
options(digits=4)
options(scipen = 999)
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
comment = NA,
tidy = TRUE)
theme_set(theme_light())
homes <- readRDS(file="/Volumes/TOSHIBAEXT/google_drive/acastillogill/content/homes.rds")
homes <- homes%>%
select(-Id)
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes,
method = "anova")
# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)
# Plot the "CP Table"
plotcp(homes_model)
# Print the "CP Table"
print(homes_model$cptable)
0.3226+0.03111
#Computing predicted values on the test set (NOT the training test)
pred_base <- predict(object=homes_model,
newdata = homes)
library(Metrics)
rmse_base <- rmse(actual=homes$SalePrice, #Actual values
predicted = pred_base)
mae_base <- mae(actual=homes$SalePrice, #Actual values
predicted = pred_base )
rmse_base
mae_base
# Retrieve optimal cp value based on cross-validated error
opt_index <- 8
cp_opt <- homes_model$cptable[opt_index, "CP"]
# Prune the model (to optimized cp value)
homes_model_opt <- prune(tree = homes_model,
cp = cp_opt)
# Plot the optimized model
rpart.plot(x = homes_model_opt, type = 5, extra = 1)
#Computing predicted values
pred_opt <- predict(object=homes_model_opt,
newdata = homes)
#Compute RMSE
rmse_opt <- rmse(actual=homes$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
#Compute MAE
mae_opt <- mae(actual=homes$SalePrice, #Actual values
predicted = pred_opt) #Predicted values
rmse_opt
