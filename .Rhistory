# Chunk 4: hierarchical-clustering-single
#Hierarchical clustering by single linkage
hc_cereals_single <- hclust(dist_cereals, method = "single")
#Selecting two clusters
clusters_k2_single <- cutree(hc_cereals_single, k=2)
#Appending the clusters to all the dataset
cereals_k2_single <- mutate(cereals, cluster=clusters_k2_single)
single_count <- count(cereals_k2_single, cluster)
# Chunk 5: hierarchical-clustering-average
#Hierarchical clustering by average linkage
hc_cereals_average <- hclust(dist_cereals, method = "average")
#Selecting two clusters
clusters_k2_average <- cutree(hc_cereals_average, k=2)
#Appending the clusters to all the dataset
cereals_k2_average <- mutate(cereals, cluster=clusters_k2_average)
average_count <- count(cereals_k2_average, cluster)
# Chunk 6: plot-complete-linkage
dend_cereals_comp <- as.dendrogram(hc_cereals_complete)
dend_colored_comp <- color_branches(dend_cereals_comp, k=2)
plot(dend_colored_comp)
# Chunk 7: plot-average-linkage
dend_cereals_av <- as.dendrogram(hc_cereals_average)
dend_colored_av <- color_branches(dend_cereals_av, k=2)
plot(dend_colored_av)
# Chunk 8: plot-single-linkage
dend_cereals_sin <- as.dendrogram(hc_cereals_single)
dend_colored_sin <- color_branches(dend_cereals_sin, k=2)
plot(dend_colored_sin)
# Chunk 9: mean-for-each-cluster
two_clusters <- cereals_k2_complete %>%
select(-shelf,-name,-mfr,-type)%>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))%>%
cbind(complete_count$n)
kable(two_clusters, caption="")%>%
kable_styling()
#Remove categorical variables
num_cereals <- cereals[,4:16]
#Remove shelf
#num_cereals$shelf <- NULL
#num_cereals$weight <- NULL
num_cereals$cups <- NULL
#scale numeric variables
num_cereals <- scale(num_cereals)
#Calculate distances
dist_cereals <- dist(num_cereals, method = "euclidean")
#Hierarchical clustering by complete linkage
hc_cereals_complete <- hclust(dist_cereals, method = "complete")
#Selecting two clusters
clusters_k2_complete <- cutree(hc_cereals_complete, k=2)
#Appending the clusters to all the dataset
cereals_k2_complete <- mutate(cereals, cluster=clusters_k2_complete)
complete_count <- count(cereals_k2_complete, cluster)
complete_count
dist_cereals
dend_cereals_comp <- as.dendrogram(hc_cereals_complete)
dend_colored_comp <- color_branches(dend_cereals_comp, k=2)
plot(dend_colored_comp)
names(num_cereals)
num_cereals
#Hierarchical clustering by complete linkage
hc_cereals_complete <- hclust(dist_cereals, method = "complete")
#Selecting two clusters
clusters_k2_complete <- cutree(hc_cereals_complete, k=2)
#Appending the clusters to all the dataset
cereals_k2_complete <- mutate(cereals, cluster=clusters_k2_complete)
complete_count <- count(cereals_k2_complete, cluster)
complete_count
dend_cereals_comp <- as.dendrogram(hc_cereals_complete)
dend_colored_comp <- color_branches(dend_cereals_comp, k=2)
plot(dend_colored_comp)
two_clusters <- cereals_k2_complete %>%
select(-shelf,-name,-mfr,-type)%>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))%>%
cbind(complete_count$n)
kable(two_clusters, caption="")%>%
kable_styling()
two_clusters <- cereals_k2_complete %>%
select(-shelf,-name,-mfr,-type,-cups)%>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))%>%
cbind(complete_count$n)
kable(two_clusters, caption="")%>%
kable_styling()
two_clusters <- cereals_k2_complete %>%
select(-shelf,-name,-mfr,-type,-cups,-weight)%>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))%>%
cbind(complete_count$n)
kable(two_clusters, caption="")%>%
kable_styling()
two_clusters[2,]/two_clusters[1,]
shelf_cluster <- table(cereals_k2_complete$shelf,cereals_k2_complete$cluster)
colnames(shelf_cluster) <- c("Cluster 1","    Cluster 2")
shelf_cluster%>%
kable(row.names = TRUE, caption="The top shelf (3), has an equal quantity of cereals belonging to either cluster. The bottom shelf has almost twice as doubl cluster 2 cereals. Finally, the middle shelf has almost as three times cluster 2 cereals.")%>%
kable_styling()
ggplot(cereals_k2_complete, aes(x = sugars, y = shelf, color = factor(cluster))) +
geom_point(alpha=0.5)+
scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
scale_y_continuous(breaks=c(1,2,3))+
labs(title="Which shelf has the most sugary cereals?",
x="Sugar content per serving",
y="Supermarket shelf: from the floor (1) to the top (3)")
shelf_cluster <- table(cereals_k2_complete$shelf,cereals_k2_complete$cluster)
colnames(shelf_cluster) <- c("Cluster 1","    Cluster 2")
shelf_cluster%>%
kable(row.names = TRUE, caption="The top shelf (3), has an equal quantity of cereals belonging to either cluster. The bottom shelf has almost twice as doubl cluster 2 cereals. Finally, the middle shelf has almost as three times cluster 2 cereals.")%>%
kable_styling()
blogdown::serve_site()
ggplot(cereals_k2_complete, aes(x = vitamins, y = shelf, color = factor(cluster))) +
geom_point(alpha=0.5)+
scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
scale_y_continuous(breaks=c(1,2,3))+
labs(title="Which shelf has the most sugary cereals?",
x="Sugar content per serving",
y="Supermarket shelf: from the floor (1) to the top (3)")
ggplot(cereals_k2_complete, aes(x = sodium, y = shelf, color = factor(cluster))) +
geom_point(alpha=0.5)+
scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
scale_y_continuous(breaks=c(1,2,3))+
labs(title="Which shelf has the most sugary cereals?",
x="Sugar content per serving",
y="Supermarket shelf: from the floor (1) to the top (3)")
ggplot(cereals_k2_complete, aes(x = fiber, y = shelf, color = factor(cluster))) +
geom_point(alpha=0.5)+
scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
scale_y_continuous(breaks=c(1,2,3))+
labs(title="Which shelf has the most sugary cereals?",
x="Sugar content per serving",
y="Supermarket shelf: from the floor (1) to the top (3)")
ggplot(cereals_k2_complete, aes(x = sodium, y = shelf, color = factor(cluster))) +
geom_point(alpha=0.5)+
scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
scale_y_continuous(breaks=c(1,2,3))+
labs(title="Which shelf has the most sugary cereals?",
x="Sugar content per serving",
y="Supermarket shelf: from the floor (1) to the top (3)")
ggplot(cereals_k2_complete, aes(x = sodium, y = shelf, color = factor(cluster))) +
geom_point(alpha=0.5)+
scale_color_manual(values=c("#1F78B4" , "#E31A1C"))+
geom_text_repel(aes(label=name), force=2, size=3, segment.alpha = 0.5)+
scale_y_continuous(breaks=c(1,2,3))+
labs(title="Which shelf has the most sodium-rich cereals?",
x="Sodium content per serving",
y="Supermarket shelf: from the floor (1) to the top (3)")
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
#Look at variable importance
var_importance <- tidy(homes_model$variable.importance)
total_importance <- sum(var_importance$x)
var_importance%>%
mutate(names=fct_reorder(names,x))%>%
head(15)%>%
ggplot(aes(names,x/total_importance,fill=names))+
geom_col()+
scale_y_continuous(labels = scales::percent_format())+
coord_flip()+
labs(title="Top 15 variables for predicting SalePrice",
y="",
x="")+
theme(legend.position = "none")
# Chunk 1: setup
x <-
c("tidyverse",
"knitr",
"formatR",
"stringr",
"lubridate",
"tidyr",
"formattable",
"grid",
"gridExtra",
"kableExtra",
"here",
"corrplot",
"rms",
"dummies",
"sjmisc",
"car",
"DescTools",
"gvlma",
"MASS",
"QuantPsyc",
"Hmisc",
"GGally",
"lm.beta",
"MuMIn",
"broom",
"corrplot",
"rpart",
"rpart.plot",
"Metrics",
"caret",
"psych",
"hrbrthemes")
lapply(x, require, character.only = TRUE)
theme_set(theme_ipsum_rc())
opts_chunk$set(echo = FALSE,
warning = FALSE,
error = FALSE,
message = FALSE,
collapse= TRUE,
tidy = TRUE,
cache=FALSE,
comment = NA,
results ='asis')
options(scipen = 999)
options(digits=4)
# Chunk 2: reading data
path <- here::here("static","data","property_train.csv")
#Read `train.csv` as homes
homes <- read.csv(path, stringsAsFactors = FALSE)
# Chunk 3: counting variable types
#is.numeric returns TRUE if the variable is numeric.
#sapply iterates and returns a vector.
#Which gives the indices that were TRUE
num_var <- which(sapply(homes, is.numeric))
#Count how many variables are numeric
length_num_var <- length(num_var)
#Return a vector with character variables
car_var <- which(sapply(homes, is.character))
#Count how many variables are characters
length_car_var <- length(car_var)
# Chunk 4: missigness-table
#Which variables have missingness in data
homes%>%
dplyr::select_if(function (x) any(is.na(x)))%>%
dplyr::summarise_all(funs(sum(is.na(.))))%>%
gather()%>%
arrange(desc(value))->missing_columns
# Chunk 5: missingness and recoding ordinal variables
#Vector for ordinal values
ordinal_scale <- c("Ex"=5, "Gd"=4, "TA"=3, "Fa"=2, "Po"=1, "No"=0)
#Missingness PoolQC
homes$PoolQC[is.na(homes$PoolQC)] <- "No"
#Recode PoolQC
homes$PoolQC<-as.integer(plyr::revalue(homes$PoolQC, ordinal_scale))
#Missingness MiscFeature
homes$MiscFeature[is.na(homes$MiscFeature)] <- "No"
#Recode MiscFeature
homes$MiscFeature <- as.factor(homes$MiscFeature)
#Missingness Alley
homes$Alley[is.na(homes$Alley)] <- "No"
#Recode Alley
homes$Alley <- as.factor(homes$Alley)
#Missingness Fence
homes$Fence[is.na(homes$Fence)] <- "No"
#Checking if Fence is ordinal
homes%>%
filter(!is.na(SalePrice))%>%
group_by(Fence) %>%
dplyr::summarise(median = median(SalePrice), counts=n())
#Fence is not ordinal
#Recode Fence
homes$Fence <- as.factor(homes$Fence)
#Missingness FireplaceQu
homes$FireplaceQu[is.na(homes$FireplaceQu)] <- "No"
#Checking if FireplaceQu is ordinal
homes%>%
filter(!is.na(SalePrice))%>%
group_by(FireplaceQu) %>%
dplyr::summarise(median = median(SalePrice), counts=n())
#Recode FireplaceQu
homes$FireplaceQu<-as.integer(plyr::revalue(homes$FireplaceQu, ordinal_scale))
#LotFrontage is the linear feet of street connnected to property
#Missing values will be replaced by neighborhood average
for (i in 1:nrow(homes)){
if(is.na(homes$LotFrontage[i])){
homes$LotFrontage[i] <-
as.integer(median(homes$LotFrontage[homes$Neighborhood==homes$Neighborhood[i]], na.rm=TRUE))
}
#Missingness GarageType
homes$GarageType[is.na(homes$GarageType)] <- "No"
#Recode GarageType
homes$GarageType <- as.factor(homes$GarageType)
#Checking if GarageFinish is ordinal
homes%>%
filter(!is.na(SalePrice))%>%
group_by(GarageFinish) %>%
dplyr::summarise(median = median(SalePrice), counts=n())
#It is ordinal
#Missingness GarageFinish
homes$GarageFinish[is.na(homes$GarageFinish)] <- "No"
#GarageFinish ordinal vector
Finish <- c('No'=0, 'Unf'=1, 'RFn'=2, 'Fin'=3)
#Recode GarageFinish
homes$GarageFinish<-as.integer(plyr::revalue(homes$GarageFinish, Finish))
table(homes$GarageFinish)
#Missingness GarageQual
homes$GarageQual[is.na(homes$GarageQual)] <- "No"
#Recode GarageQual
homes$GarageQual<-as.integer(plyr::revalue(homes$GarageQual, ordinal_scale))
#Missingness GarageCond
homes$GarageCond[is.na(homes$GarageCond)] <- "No"
#Recode GarageCond
homes$GarageCond<-as.integer(plyr::revalue(homes$GarageCond, ordinal_scale))
#Missingness GarageYrBlt will be substituted for YearBuilt
#For all rows in homes
for (i in 1:nrow(homes)){
#If observation i of column GarageYrBlt is NA
if(is.na(homes$GarageYrBlt[i])){
#Change observation for observation i of column YearBuilt
homes$GarageYrBlt[i] <- homes$YearBuilt[i]
}
#Checking if BsmtExposure is ordinal
homes%>%
filter(!is.na(SalePrice))%>%
group_by(BsmtExposure) %>%
dplyr::summarise(median = median(SalePrice), counts=n())
#Missingness BsmtExposure
homes$BsmtExposure[is.na(homes$BsmtExposure)] <- "None"
#It is ordinal, create vector substitute vector
exposure_ordinal <- c("Gd"= 4,"Av"= 3,"Mn"=2,"No"=1, "None"=0)
#Recode BsmtExposure
homes$BsmtExposure<-as.integer(plyr::revalue(homes$BsmtExposure, exposure_ordinal))
table(homes$BsmtExposure)
#Checking if BsmtFinType2 is ordinal
homes%>%
filter(!is.na(SalePrice))%>%
group_by(BsmtFinType2) %>%
dplyr::summarise(median = median(SalePrice), counts=n())
#Missingness BsmtFinType2
homes$BsmtFinType2[is.na(homes$BsmtFinType2)] <- "No"
#It is ordinal, create vector substitute vector
FinType_ordinal <- c('No'=0, 'Unf'=1, 'LwQ'=2, 'Rec'=3, 'BLQ'=4, 'ALQ'=5, 'GLQ'=6)
#Recode BsmtFinType2
homes$BsmtFinType2<-as.integer(plyr::revalue(homes$BsmtFinType2, FinType_ordinal))
table(homes$BsmtFinType2)
#Missingness BsmtQual
homes$BsmtQual[is.na(homes$BsmtQual)] <- "No"
#Recode BsmtQual
homes$BsmtQual<-as.integer(plyr::revalue(homes$BsmtQual, ordinal_scale))
#Missingness BsmtCond
homes$BsmtCond[is.na(homes$BsmtCond)] <- "No"
#Recode BsmtCond
homes$BsmtCond<-as.integer(plyr::revalue(homes$BsmtCond, ordinal_scale))
#Missingness BsmtFinType1
homes$BsmtFinType1[is.na(homes$BsmtFinType1)] <- "No"
#Recode BsmtFinType1
homes$BsmtFinType1<-as.integer(plyr::revalue(homes$BsmtFinType1, FinType_ordinal))
table(homes$BsmtFinType1)
#Checking if MasVnrType is ordinal
homes%>%
filter(!is.na(SalePrice))%>%
group_by(MasVnrType) %>%
dplyr::summarise(median = median(SalePrice), counts=n())
#Missingness MasVnrType
homes$MasVnrType[is.na(homes$MasVnrType)] <- "None"
#Create ordinality vector
mas_ordinality <- c('None'=0, 'BrkCmn'=0, 'BrkFace'=1, 'Stone'=2)
#Recode MasVnrType
homes$MasVnrType<-as.integer(plyr::revalue(homes$MasVnrType, mas_ordinality))
table(homes$MasVnrType)
#Missingness MasVnrArea
homes$MasVnrArea[is.na(homes$MasVnrArea)] <- 0
#Missingness Electrical
homes%>%
group_by(Electrical)%>%
dplyr::count()%>%
arrange(desc(n))%>%
dplyr::select(Electrical)%>%
head(n=1)->replacement_Electrical
homes$Electrical[is.na(homes$Electrical)] <- unlist(replacement_Electrical)
#Recode Electrical
homes$Electrical <- as.factor(homes$Electrical)
#Recode MSZoning
homes$MSZoning  <- as.factor(homes$MSZoning)
#Recode MSSubClass
homes$MSSubClass  <- as.factor(homes$MSSubClass)
#Recode Street
homes$Street  <- as.factor(homes$Street)
#Recode LotShape
homes$LotShape   <- as.factor(homes$LotShape)
#Recode LandContour
homes$LandContour   <- as.factor(homes$LandContour)
#Recode Utilities
homes$Utilities    <- as.factor(homes$Utilities)
#Looking at factors
table(homes$Utilities)
#When looking at levels, all observations except 1, fall into one level. Therefore this variable is not too helpful.
homes$Utilities <- NULL
#Recode LotConfig
homes$LotConfig     <- as.factor(homes$LotConfig)
#Recode LandSlope
homes$LandSlope     <- as.factor(homes$LandSlope)
#Recode Neighborhood
homes$Neighborhood     <- as.factor(homes$Neighborhood)
#Recode Condition1
homes$Condition1     <- as.factor(homes$Condition1)
#Recode Condition2
homes$Condition2     <- as.factor(homes$Condition2)
#Recode BldgType
homes$BldgType      <- as.factor(homes$BldgType)
#Recode HouseStyle
homes$HouseStyle       <- as.factor(homes$HouseStyle)
#Recode RoofStyle
homes$RoofStyle       <- as.factor(homes$RoofStyle)
#Recode RoofMatl
homes$RoofMatl      <- as.factor(homes$RoofMatl)
#Recode Exterior1st
homes$Exterior1st       <- as.factor(homes$Exterior1st)
#Recode Exterior2nd
homes$Exterior2nd       <- as.factor(homes$Exterior2nd)
#Recode ExterQual
homes$ExterQual<-as.integer(plyr::revalue(homes$ExterQual, ordinal_scale))
#Recode ExterCond
homes$ExterCond<-as.integer(plyr::revalue(homes$ExterCond, ordinal_scale))
#Recode Foundation
homes$Foundation      <- as.factor(homes$Foundation)
#Recode Heating
homes$Heating       <- as.factor(homes$Heating)
#Recode HeatingQC
homes$HeatingQC<-as.integer(plyr::revalue(homes$HeatingQC, ordinal_scale))
#Recode CentralAir
boolean <- c("Y"=1,"N"=0)
homes$CentralAir<-as.integer(plyr::revalue(homes$CentralAir, boolean))
table(homes$CentralAir)
#Recode KitchenQual
homes$KitchenQual<-as.integer(plyr::revalue(homes$KitchenQual, ordinal_scale))
#Recode Functional
homes$Functional      <- as.factor(homes$Functional)
#Recode PavedDrive
homes$PavedDrive       <- as.factor(homes$PavedDrive)
#Recode SaleType
homes$SaleType        <- as.factor(homes$SaleType)
#Recode SaleCondition
homes$SaleCondition     <- as.factor(homes$SaleCondition)
# Chunk 6: create time variables
homes<-homes%>%
#Mutate to create `YearsSinceBuilt`, `YearsSinceGarageBuilt`, and `YearsSinceRemod`
#It will be the difference of the present year - YearBuilt
mutate(YearsSinceBuilt = year(Sys.Date())-YearBuilt,
#Same for YearsSinceRemod
YearsSinceRemod = year(Sys.Date())-YearRemodAdd,
#Same for GarageYrBlt
YearsSinceGarageBuilt = year(Sys.Date())-GarageYrBlt)%>%
#Remove old variables, correlated ones, and ID
dplyr::select(-GarageYrBlt,
-YearRemodAdd,
-YearBuilt,
-GarageCars,
-BsmtQual,
-TotRmsAbvGrd,
-Id)
# Chunk 7: understanding-neighborhood-var
homes%>%
group_by(Neighborhood)%>%
summarise(Median=median(SalePrice))%>%
arrange(desc(Median))%>%
ggplot(aes(x=reorder(Neighborhood, Median), y=Median))+
geom_col()+
labs(title="Neighborhoods vs. Average SalePrice",
x="Neighborhood")+
scale_y_continuous(labels = scales::dollar_format(suffix = "", prefix = "$")) + coord_flip()
# Chunk 8: binning_neighboorhood
fancy <- c("NridgHt","NoRidge","StoneBr")
modern <- c("20","60","70","80","85","120")
homes <- homes%>%
mutate(Neighborhood_type=ifelse(Neighborhood %in% fancy, "Fancy","Not_fancy"),
MS_type=ifelse(MSSubClass %in% modern, "Modern","Less_modern"))
homes <- homes%>%
dplyr::select(-Neighborhood,
-MSSubClass)
# Chunk 10: covariance-example
cov(scale(homes$SalePrice), scale(homes$OverallQual))
# Chunk 11: single-regression-normalised-data
norm_fit <- lm(scale(SalePrice) ~ scale(KitchenQual), data = homes)
round(coefficients(norm_fit), digits = 2)
# Chunk 12: correlation-matrix
homes_num <- homes%>%
select_if(is.numeric)
#Create tidy correlation matrix
cor_homes <- tidy(cor(homes_num))
#Arrange correlations with SalePrice in descending order
high_cor_names <- cor_homes%>%
arrange(desc(SalePrice))%>%
filter(abs(SalePrice)>0.5)%>%#Filter variables that have relationship >0.5
pull(.rownames)#Pull names of variables
#Filter entire correlation matrix for the variables
high_cor <- cor(homes_num)[high_cor_names,high_cor_names]
#Create correlation matrix
corrplot.mixed(high_cor, tl.col="black", tl.pos = "lt",cl.ratio=0.1,number.cex=.6, cl.cex = .6, tl.cex = 0.6)
# Chunk 13
homes <- homes%>%
mutate(SalePrice=SalePrice/1000)
# Chunk 14: split-data
# Randomly assign rows to ids (1/2) represents train/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/test split will be approximately 70% / 30%
set.seed(1)
assignment <- sample(1:2, size = nrow(homes),
prob = c(0.7,0.3),
replace = TRUE)
# Create a train, validation and tests from the original data frame
homes_train <- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_test <- homes[assignment == 2, ]   # subset the homes data frame to test indices only
# Chunk 15: train the model
# Train the model
homes_model <- rpart(formula = SalePrice ~ .,
data = homes_train,
method = "anova")
library(tidylog)
homes_model$variable.importance
tidy(homes_model$variable.importance)
