<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ángela Castillo-Gill on Ángela Castillo-Gill</title>
    <link>/</link>
    <description>Recent content in Ángela Castillo-Gill on Ángela Castillo-Gill</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ángela Castillo-Gill</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The perfect balance</title>
      <link>/note/the-perfect-balance/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/the-perfect-balance/</guid>
      <description>


&lt;div id=&#34;daily-goals&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Daily goals:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Discuss the proposed answer for yesterday’s question: why did the performance metrics go up?&lt;/li&gt;
&lt;li&gt;Talk about next steps for the property values post.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-discuss-the-proposed-answer-for-yesterdays-question-why-did-the-performance-metrics-go-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Discuss the proposed answer for yesterday’s question: why did the performance metrics go up?&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the base model &lt;code&gt;homes_model&lt;/code&gt; is 36182.1117 and the &lt;code&gt;mae&lt;/code&gt; is 25797.5518.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the improved model &lt;code&gt;homes_model_opt&lt;/code&gt; is 40848.44 and the &lt;code&gt;mae&lt;/code&gt; is 28394.1.&lt;/p&gt;
&lt;p&gt;Yesterday I was pretty annoyed because I didn’t understand why the smallest tree with lowest cross validated error had worse performance metrics than a large tree. Like, mmm, why?&lt;/p&gt;
&lt;p&gt;So I kind of felt I was hitting a dead end and decided to take to trusty old Stack Overflow to ASK FOR HELP. I asked and I received.&lt;/p&gt;
&lt;p&gt;I received two helpful in less than twelve hours (Stack Overflow never change). The first suggested I consult the book Introduction to Statistical Learning from Springer. I have obtained it and it will be my reference book right after the one I’m currently doing called Regression Models. I have looked at the Table of Contents and it has a chapter dedicated to trees so that will come very much in handy.&lt;/p&gt;
&lt;p&gt;The second answer was this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is always a balance between a tree big enough to represent the variation in the data and not so big that it overfits. The reason that bigger trees sometimes produce better results is that they more finely partition the data and so represent nuances. The reason that smaller trees sometimes produce better results is that there is less of a problem with overfitting. But if the smallest tree was always the best, the why not just use one node? Just using the root node would estimate the value using the average - not likely to be really accurate. The two conflicting forces must be balanced to get the best result.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My initial thoughts yesterday were that because a smaller tree, was ummm, well, smaller, it would have better performance on unseen data than a larger tree.&lt;/p&gt;
&lt;p&gt;That line they use:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But if the smallest tree was always the best, the why not just use one node?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Really captures my inital assumption. Exactly, if a smaller tree is always better, why not just use the smallest tree possible, the root node.&lt;/p&gt;
&lt;p&gt;And so the mystery is partially solved in that actually the bigger tree did perform better.&lt;/p&gt;
&lt;p&gt;I will consult the book chapter now to see if I can see any immediately useful tips. Wow! That book is super helfpul and explains well how the &lt;code&gt;RPart&lt;/code&gt; algorithm works. I look forward to moving on to it soon.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-talk-about-next-steps-for-the-property-values-post.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Talk about next steps for the property values post.&lt;/h2&gt;
&lt;p&gt;So now that we’ve decided that the larger tree is better, there is also an option where we use the data split we haven’t used to tune the model’s hyperparamters that we talked about in previous posts.&lt;/p&gt;
&lt;p&gt;I would think the next steps are to do that with the tree that performs better and see if we can get any improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;grid-search-for-best-hyperparameters-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Grid search for best hyperparameters &lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# Establish a list of possible values for minsplit and maxdepth From 1 to 30
# by 5
min_split &amp;lt;- seq(1, 10, 1)
# From 1 to 30 by 1
max_depth &amp;lt;- seq(1, 30, 1)

# Create a dataframe containing all combinations
hyper_grid &amp;lt;- expand.grid(min_split = min_split, max_depth = max_depth)

# Check dimensions
dim(hyper_grid)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create an empty list to store the models

models &amp;lt;- list()

# Execute the grid search

for (i in 1:nrow(hyper_grid)) {
    
    # Get min_split, max_depth values at row i
    
    minsplit &amp;lt;- hyper_grid$min_split[i]
    max_depth &amp;lt;- hyper_grid$max_depth[i]
    
    # Train the model and store in the list
    
    models[[i]] &amp;lt;- rpart(formula = SalePrice ~ ., data = homes_train, method = &amp;quot;anova&amp;quot;, 
        minsplit = min_split, maxdepth = max_depth)
    
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create an empty vector to store RMSE values
rmse_values &amp;lt;- c()
# Create an empty vector to store MAE values
mae_values &amp;lt;- c()

# Compute validation RMSE
for (i in 1:length(models)) {
    
    # Retrieve the ith model from the list
    
    model &amp;lt;- models[[i]]
    
    # Generate predictions on homes_valid validation set
    
    pred_grid &amp;lt;- predict(object = model, newdata = homes_valid)
    
    # Compute validation RMSE and add to the
    
    rmse_values[i] &amp;lt;- rmse(actual = homes_valid$SalePrice, predicted = pred_grid)
    
    mae_values[i] &amp;lt;- mae(actual = homes_valid$SalePrice, predicted = pred_grid)
    
    
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Identifying the model with smallest validation set RMSE
best_model_RMSE &amp;lt;- models[[which.min(rmse_values)]]
# Print the model parameters of the best_model_RMSE
best_model_RMSE$control
# Compute test set RMSE on best_model_RMSE
pred &amp;lt;- predict(object = best_model_RMSE, newdata = homes_test)

rmse(actual = homes_test$SalePrice, predicted = pred)

# Identifying the model with smallest validation set MAE
best_model_MAE &amp;lt;- models[[which.min(mae_values)]]
# Print the model parameters of the best_model_MAE
best_model_MAE$control
# Compute test set MAE on best_model_MAE
pred &amp;lt;- predict(object = best_model_MAE, newdata = homes_test)

mae(actual = homes_test$SalePrice, predicted = pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/note/Thursday-22-11-2018_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is something wrong I think because the best tree after grid search has an &lt;code&gt;RMSE&lt;/code&gt; higher than the base tree. And then if we look at the RMSE values resulting from the grid search they are all the same so it seems like the tree doesn’t attempt any splits. WHY?
Another why?&lt;/p&gt;
&lt;p&gt;I think instead of doing this grid search which needs a proper study, I’m going to write up the full post and everything I’ve done with the Kaggle dataset. Better to talk about the interpretability and the next bits too.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Code from here until the end of the post was adapted from DataCamp’s course on Machine Learning with Trees.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why did error go up?</title>
      <link>/note/why-did-error-go-up/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/why-did-error-go-up/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Figure out why the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; went up when I chose an “improved” tree.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-figure-out-why-the-rmse-and-mse-went-up-when-i-chose-an-improved-tree.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Figure out why the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; went up when I chose an “improved” tree.&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the base model &lt;code&gt;homes_model&lt;/code&gt; is 36182.1117 and the &lt;code&gt;mae&lt;/code&gt; is 25797.5518.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the improved model &lt;code&gt;homes_model_opt&lt;/code&gt; is 40848.44 and the &lt;code&gt;mae&lt;/code&gt; is 28394.1.&lt;/p&gt;
&lt;p&gt;This shouldn’t be the case, or should it?&lt;/p&gt;
&lt;p&gt;Let’s think what an increase in these two types of performance metrics mean. In the &lt;code&gt;rmse&lt;/code&gt; case, yesterday we saw that this is a measure of how much the fit deviates from real values.
An increase of 4666.3268 means that the pruned model is a worse fit. WHY? Shouldn’t a smaller tree prevent overfitting?&lt;/p&gt;
&lt;p&gt;I’ve just posted the question on Stack Overflow because right now I don’t have any ideas… maybe there is nothing wrong with performance metrics going up? But that doesn’t make sense. Wasn’t the whole process of choosing the best &lt;code&gt;cp_index&lt;/code&gt; to choose a tree with improved performance?&lt;/p&gt;
&lt;p&gt;I am very confused. It doesn’t make sense. I am going to look at the documentation again to see if I can find anything on performance metrics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An objective measure</title>
      <link>/note/an-objective-measure/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/an-objective-measure/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Evaluate the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; in the base and improved tree.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-evaluate-the-rmse-and-mse-in-the-base-and-improved-tree.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Evaluate the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; in the base and improved tree.&lt;/h2&gt;
&lt;p&gt;Right. So we know from previous posts that we pick the smallest tree within one standard error of the lowest &lt;code&gt;xerror&lt;/code&gt;. Eggsellent. BUT. What can we use to objectively measure the difference between trees? We can use the error between a less pruned tree and the improved one.&lt;/p&gt;
&lt;p&gt;There are two measurements of error, the &lt;code&gt;rmse&lt;/code&gt; and the &lt;code&gt;mae&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The root mean square error (RMSE) or root mean standard deviation (RMSD) is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[RMSD =\sqrt {\frac {\sum _{i=1}^{n}({\hat {y}}_{i}-y_{i})^{2}}{n}}\]&lt;/span&gt;
Where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the sample size, and &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{i}\)&lt;/span&gt; are the predicted values for the dependent variable &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Without reading the definition, this looks like it it “punishing” the differences between the estimated values and actual values, then dividing it per observation and taking the square root so the units are the actual ones for the response variable.&lt;/p&gt;
&lt;p&gt;The other &lt;em&gt;performance metric&lt;/em&gt;, which is the actual name for these tree-measuring-metrics, is called the &lt;code&gt;MAE&lt;/code&gt;. Which I think stands for the mean absolute error is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[MAE ={\frac {\sum _{i=1}^{n}\left|y_{i}-\hat {y_i}\right|}{n}}\]&lt;/span&gt;
It seems like the difference here is that the &lt;code&gt;RMSE&lt;/code&gt; punishes differences while the &lt;code&gt;MAE&lt;/code&gt; doesn’t emphasise large differences as much.&lt;/p&gt;
&lt;p&gt;Now let’s calculate these performance metrics for the original tree and then the pruned tree.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:basic-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Tuesday-20-11-2018_files/figure-html/basic-model-1.png&#34; alt=&#34;A first model suggests 9 splits with 10 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A first model suggests 9 splits with 10 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the base model &lt;code&gt;homes_model&lt;/code&gt; is 4.68910^{4} and the &lt;code&gt;mae&lt;/code&gt; is 3.16810^{4}.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:improved-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Tuesday-20-11-2018_files/figure-html/improved-model-1.png&#34; alt=&#34;Improved model has 7 splits and 8 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Improved model has 7 splits and 8 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the improved model &lt;code&gt;homes_model_opt&lt;/code&gt; is 4.99610^{4} and the &lt;code&gt;mae&lt;/code&gt; is 3.39110^{4}.&lt;/p&gt;
&lt;p&gt;Ugh oh. It has gone up. Something is wrong. Why?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The basics</title>
      <link>/note/the-basics/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/the-basics/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Go over the difference between standard deviation, variance, and standard error.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Evaluate the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; in the base and improved tree.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-go-over-the-difference-between-standard-deviation-variance-and-standard-error.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Go over the difference between standard deviation, variance, and standard error.&lt;/h2&gt;
&lt;p&gt;So in a few machine learning algorithms, if not all of them, there are three terms that are contantly being used with “mean” and “median”: Standard deviation, variance, and standard error. I have probably studied these three terms and written their formulas too many times to mention here and you know what? If you asked me right now to explain the difference with every day examples, I don’t think I could. Over time they have become a mush and I realise the reason they don’t stick is because they are something I haven’t associated with something that makes sense to me.&lt;/p&gt;
&lt;p&gt;So today I will define these world-renowned measures of dispersion today and try to come up with examples from my every day life.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sample variance:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s^2 = \frac{1}{N-1} \sum_{i=1}^N (x_i - \overline{x})^2\]&lt;/span&gt;
Where, &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is the sample size; &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is the observation or piece of data, and &lt;span class=&#34;math inline&#34;&gt;\(\overline{x}\)&lt;/span&gt; is the data set mean.&lt;/p&gt;
&lt;p&gt;The differences between each point and the mean are squared to avoid negative differences cancelling positive ones. The variance units are the mean units squared.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Today I went for my grocery shop so let’s work from there. Let’s say I add lemons (1.68), apples (1.9), grapes (1.4), bananas (.97), and pine nuts (5.4) to my receipt.&lt;/p&gt;
&lt;p&gt;Then I ask, I wonder what the average price of each ingredient was, so I add and divide to create a simple average.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grocery_bill&amp;lt;- c(1.68,1.9,1.4,0.97,5.4)
sum(grocery_bill)/length(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2.27, fabulous. Now, I want to see how much variation there is amongst each ingredient.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grocery_bill-mean(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.59 -0.37 -0.87 -1.30  3.13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems like the last two items, bananas and pine nuts varied quite a bit more from the mean. Let’s add the differences now because let’s say I want to show my husband how bigger the difference is when we add pine nuts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(grocery_bill-mean(grocery_bill))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They have cancelled out. I think this is what you do when you want the regression line to go through the origin.&lt;/p&gt;
&lt;p&gt;In order to take each difference without it cancelling out, we SQUARE. AHA. Ok. I think maybe this will help it stick.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum((grocery_bill-mean(grocery_bill))^2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12.7288&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, now we divide by the 5 items.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sum((grocery_bill-mean(grocery_bill))^2))/5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.54576&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.1822&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I also computed the variance with base R and they were different. Why? Because I forgot the &lt;span class=&#34;math inline&#34;&gt;\(N-1\)&lt;/span&gt; bit. Classic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sum((grocery_bill-mean(grocery_bill))^2))/4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.1822&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.1822&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now they are the same. But why do we substract &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt;. It seems the answer is because we want to have an unbiased estimator and it’s called the &lt;em&gt;Bessel’s correction&lt;/em&gt; (?????).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sample standard deviation:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (x_i -\overline{x})^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now, the sample standard deviation is just the square root of the variance. It has the same units as the mean. On our groceries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt((sum((grocery_bill-mean(grocery_bill))^2))/4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.783872&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.783872&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is the same! Ok. Well done. So 1.78 Euros is how much each item of my grocery list on average deviates from the mean which was 2.27.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standard error:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma_{\bar {x}}\ \approx {\frac {s}{\sqrt {n}}}\]&lt;/span&gt;
So from what I can see it’s the sample standard deviation divided by the square root of the sample size. mmmm, but why?&lt;/p&gt;
&lt;p&gt;According to Wikipedia: &lt;em&gt;The standard error (SE) of a statistic (usually an estimate of a parameter) is the standard deviation of its sampling distribution…&lt;/em&gt;
mmmmm ok.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;or an estimate of that standard deviation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Looking at the formula, this latter definition makes more sense.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If the parameter or the statistic is the mean, it is called the standard error of the mean (SEM).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But actually, not. I don’t really get this, yet.&lt;/p&gt;
&lt;p&gt;Then it reads: &lt;em&gt;It can also be understood as the standard deviation of the error in the sample mean with respect to the true mean (or an estimate of that statistic).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I think I’m going to let this one sink for today because I gotta run.&lt;/p&gt;
&lt;p&gt;You know what, this was extremely basic but a helpful reminder I should do more often. Would be fun to compare the standard deviation between my grocery shop and my husband’s. I need a refresher like this with the median and distribution skewness.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Did the tree improve?</title>
      <link>/note/did-the-tree-improve/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/did-the-tree-improve/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Show if the variable change made the tree more interpretable.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Splitting data
# Randomly assign rows to ids (1/2/3 represents train/valid/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/valid/test split will be approximately 70% / 15% / 15% 
set.seed(1)
assignment &amp;lt;- sample(1:3, size = nrow(homes),
                     prob = c(0.7,0.15,0.15),
                     replace = TRUE)

# Create a train, validation and tests from the original data frame 
homes_train &amp;lt;- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_valid &amp;lt;- homes[assignment == 2, ]  # subset the homes data frame to validation indices only
homes_test &amp;lt;- homes[assignment == 3, ]   # subset the homes data frame to test indices only&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Train the model
homes_model &amp;lt;- rpart(formula = SalePrice ~ ., 
                     data = homes_train, 
                     method = &amp;quot;anova&amp;quot;)

# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:basic-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Fri-16-11-2018_files/figure-html/basic-model-1.png&#34; alt=&#34;A first model suggests 9 splits with 10 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A first model suggests 9 splits with 10 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now we are going to look at the CP table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot the &amp;quot;CP Table&amp;quot;
plotcp(homes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/note/Fri-16-11-2018_files/figure-html/tuning-hyperparameters-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Print the &amp;quot;CP Table&amp;quot;
print(homes_model$cptable)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            CP nsplit rel error    xerror       xstd
## 1  0.44576120      0 1.0000000 1.0034376 0.09648934
## 2  0.11362733      1 0.5542388 0.5578944 0.05448931
## 3  0.07787835      2 0.4406115 0.4760270 0.05459581
## 4  0.03461959      3 0.3627331 0.4091012 0.03666288
## 5  0.02116148      4 0.3281135 0.3979878 0.04568692
## 6  0.01818931      5 0.3069520 0.4082587 0.04732241
## 7  0.01742778      6 0.2887627 0.3937271 0.04468678
## 8  0.01671704      7 0.2713350 0.3939984 0.04468230
## 9  0.01294838      8 0.2546179 0.3677683 0.04291999
## 10 0.01000000      9 0.2416695 0.3524860 0.04281097&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According the &lt;code&gt;cptable&lt;/code&gt;, the lowest &lt;code&gt;xerror&lt;/code&gt; is in row 10, to that we add the &lt;code&gt;xstd&lt;/code&gt; error and obtain: &lt;span class=&#34;math inline&#34;&gt;\(0.39529\)&lt;/span&gt;. We see that the smallest error with &lt;code&gt;xerror&lt;/code&gt; below that is the tree with 7 splits and 8 nodes. I will use that in the improved plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Retrieve optimal cp value based on cross-validated error
opt_index &amp;lt;- 7
cp_opt &amp;lt;- homes_model$cptable[opt_index, &amp;quot;CP&amp;quot;]

# Prune the model (to optimized cp value)
homes_model_opt &amp;lt;- prune(tree = homes_model, 
                         cp = cp_opt)
                          
# Plot the optimized model
 rpart.plot(x = homes_model_opt, type = 5, extra = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:improved-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Fri-16-11-2018_files/figure-html/improved-model-1.png&#34; alt=&#34;Improved model has 7 splits and 8 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Improved model has 7 splits and 8 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Tomorrow, I will look to see if there are any objective measures of error, clue, there are! And apply them to compare both models.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Binning the neighborhood variable (for real now)</title>
      <link>/note/binning-the-neighborhood-variable-for-real-now/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/binning-the-neighborhood-variable-for-real-now/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create a new variable that captures what the variable is providing without so many levels.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-create-a-new-variable-that-captures-what-the-variable-is-providing-without-so-many-levels.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Create a new variable that captures what the variable is providing without so many levels.&lt;/h2&gt;
&lt;p&gt;As we saw yesterday from looking at the quantiles, we have 25 neighborhoods but very few houses are in the most expensive neighborhoods.&lt;/p&gt;
&lt;p&gt;I’m looking at the plot again and I realise there is something very odd with it. None of the homes costs more than 755,000 and yet the plot goes up to 30,000,000. I realised that I was adding the &lt;code&gt;SalePrice&lt;/code&gt; of individuals homes. Now here is another go with actual average &lt;code&gt;SalePrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Thurs-15-11-2018_files/Mean_sale_price.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Much better. Now we can see that &lt;code&gt;NoRidge&lt;/code&gt; has the highest average &lt;code&gt;SalePrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s look at this again in light of the quantiles,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; neigh_quant
# A tibble: 5 x 3
  names      x incomes      
  &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        
1 0%     34900 Lower        
2 25%   129975 Middle_Lower 
3 50%   163000 Lower        
4 75%   214000 Middle_Higher
5 100%  755000 Higher &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems like the top 8 neighborhoods would go into the &lt;code&gt;Higher&lt;/code&gt; bracket and none would go into the lowest.&lt;/p&gt;
&lt;p&gt;The way that I’m going to bin the neighborhoods is that I will create a variable called &lt;code&gt;Neighboord_type&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Houses that have neighborhoods with average &lt;code&gt;SalePrice&lt;/code&gt; above 200,000 will go into the level “Fancy”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Houses that have neighborhoods with average &lt;code&gt;SalePrice&lt;/code&gt; above 150,000 and below 200,000 will go into the level “Somewhat_fancy”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Houses that have neighborhoods with average &lt;code&gt;SalePrice&lt;/code&gt; above 100,000 and below 150,000 will go into the level “Not_fancy”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The rest will go into the “OK” level. Because it’s ok if you don’t live in a fancy neighborhood.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And this is what it looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Thurs-15-11-2018_files/New_var.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Job done I would say.&lt;/p&gt;
&lt;p&gt;Tomorrow I will do everything again with this new variable to see if the plot improves.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Binning the neighborhood variable</title>
      <link>/note/binning-the-neighborhood-variable/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/binning-the-neighborhood-variable/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Understand what information is the &lt;code&gt;neighboorhood&lt;/code&gt; variable providing&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a new variable that captures what the variable is providing without so many levels.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-understand-what-information-is-the-neighboorhood-variable-providing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Understand what information is the &lt;code&gt;neighboorhood&lt;/code&gt; variable providing&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(homes$Neighborhood)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shows that the variable has 25 levels. Let’s see the relationship between each level and the response variable &lt;code&gt;SalesPrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Plotting the &lt;code&gt;neighboorhood&lt;/code&gt; variable shows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Wed-14-11-2018_files/neigh_salesprice.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-create-a-new-variable-that-captures-what-the-variable-is-providing-without-so-many-levels.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Create a new variable that captures what the variable is providing without so many levels.&lt;/h2&gt;
&lt;p&gt;Let’s say we want to create a variable with four levels, these would be the quantile cuts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    0%    25%    50%    75%   100% 
 34900 129975 163000 214000 755000 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows for example that only very few neighborhoods will be in the last quantile (above &lt;code&gt;$755,000&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Tomorrow I will do the rest cause right now I gotta go.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Applying concepts learned to property prices</title>
      <link>/note/applying-concepts-learned-to-property-prices/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/applying-concepts-learned-to-property-prices/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Interpret the &lt;code&gt;cptable&lt;/code&gt; for the generic &lt;code&gt;homes_model&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Interpret the &lt;code&gt;rpart.plot&lt;/code&gt; associated to &lt;code&gt;homes_model&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bin the &lt;code&gt;neighborhood&lt;/code&gt; variable and explain why I’m doing that.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-interpret-the-cptable-for-the-generic-homes_model.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Interpret the &lt;code&gt;cptable&lt;/code&gt; for the generic &lt;code&gt;homes_model&lt;/code&gt;.&lt;/h2&gt;
&lt;p&gt;With the &lt;code&gt;homes&lt;/code&gt; data as is (just removing missing values), I fited a model to predict &lt;code&gt;SalesPrice&lt;/code&gt; using &lt;code&gt;rpart()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;homes_model &amp;lt;- rpart(formula = SalePrice ~ ., 
                     data = homes_train, 
                     method = &amp;quot;anova&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at the &lt;code&gt;cptable&lt;/code&gt; with &lt;code&gt;homes_model$cptable&lt;/code&gt;, I’ll apply the &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; rule I explained yesterday:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Tues-13-11-2018_files/cptable_rawhomes.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;First, we can see that the smallest cross-validation &lt;code&gt;xerror&lt;/code&gt; appears on row 11. Now let’s add 1 standard error &lt;code&gt;xstd&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(0.3074050+0.03541012=0.3428151\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The smallest tree with &lt;code&gt;xerror&lt;/code&gt; less than &lt;span class=&#34;math inline&#34;&gt;\(0.3428151\)&lt;/span&gt; is the tree appearing on row 8 with 8 splits and 9 nodes.&lt;/p&gt;
&lt;p&gt;Now, I look at the &lt;code&gt;plotcp(homes_model)&lt;/code&gt;, I’m confused to whether size of the tree refers to nodes or splits:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Tues-13-11-2018_files/cpplot_rawhomes.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I think it refers to nodes because the &lt;code&gt;xerror&lt;/code&gt; for the tree with 9 nodes appears on the dotted line. A dotted line that intersects the 9-tree node must mean it’s the chosen one, right? :laughing:&lt;/p&gt;
&lt;p&gt;Now, let’s run the model again, but specifying the best model, with 8 splits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Hard code best tree based on above explained analysis
opt_index &amp;lt;- 8
#Retrieve cp_opt
cp_opt &amp;lt;- homes_model$cptable[opt_index, &amp;quot;CP&amp;quot;]
# Prune the model (to optimized cp value)
homes_model_opt &amp;lt;- prune(tree = homes_model, 
                         cp = cp_opt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I suppose hard coding the number 8 instead of writing the code to pick the best tree isn’t too elegant, but bear with me. Writing clean code is not the priority right now. :hankey:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-interpret-the-rpart.plot-associated-to-homes_model.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Interpret the &lt;code&gt;rpart.plot&lt;/code&gt; associated to &lt;code&gt;homes_model&lt;/code&gt;.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rpart.plot(x = homes_model_opt, type = 5, extra = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That code produces this plot:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Tues-13-11-2018_files/rpartplot_rawhomes.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It has 8 splits and 9 nodes and we asked it to. Inside each terminal node is the number of observations which add up to 1025. Each split specifies the criteria for the observation being classified either into the left or right son.&lt;/p&gt;
&lt;p&gt;If we go back and look at the numeric variables that had the highest correlation with &lt;code&gt;SalesPrice&lt;/code&gt;, &lt;code&gt;OverallQual&lt;/code&gt; was leading followed by &lt;code&gt;GrLivArea&lt;/code&gt;. In the tree we can see that these variables appear further below &lt;code&gt;X1stFlrSF&lt;/code&gt; and &lt;code&gt;GarageArea&lt;/code&gt; appear later down.&lt;/p&gt;
&lt;p&gt;The plot shows the &lt;code&gt;neighborhood&lt;/code&gt; variable twice and in the second level. So it’s an important variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-3-bin-the-neighborhood-variable-and-explain-why-im-doing-that.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 3: Bin the &lt;code&gt;neighborhood&lt;/code&gt; variable and explain why I’m doing that.&lt;/h2&gt;
&lt;p&gt;So today I don’t think I’ll be able to the binning since my alloted time for this is almost up. But I will explain the why since it appears clearly on the graph.&lt;/p&gt;
&lt;p&gt;One of the advantages of regression trees is that they area easy to understand and visualise. Because the &lt;code&gt;neighborhood&lt;/code&gt; variable has so many levels, it is actually going against one of the reasons I picked it. The whole neighborhood variable is confusing. Explaining the key differences amongst neighborhoods is not straightforward using just the plot. So I’m going to explore what the relationship between those neighborhoods and price is tomorrow and see if I can create another variable that better reflects that relationship. Exciting! :sparkles:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hyperparameter laundry list</title>
      <link>/note/hyperparameter-laundry-list/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/hyperparameter-laundry-list/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Get clarity on how to pick the best tree.&lt;/li&gt;
&lt;li&gt;Make a laundry list of the algorithms hyperparameters.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-get-clarity-on-how-to-pick-the-best-tree.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Get clarity on how to pick the best tree.&lt;/h2&gt;
&lt;p&gt;So far, my confusion stems from the &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; (“one standard error” rule) vs. the &lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt; rule.&lt;/p&gt;
&lt;p&gt;These two threads have helped me understand WHY they are the same:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/138569/why-is-lambda-within-one-standard-error-from-the-minimum-is-a-recommended-valu&#34;&gt;What’s the deal with this whole 1-SE rule.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/13471/how-to-choose-the-number-of-splits-in-rpart&#34;&gt;Applying the 1-SE rule.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So first of all, I didn’t even understand &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; when I read it in the Rpart documentation. What does it mean? I kept searching substracting &lt;span class=&#34;math inline&#34;&gt;\(SE\)&lt;/span&gt; (which in the &lt;code&gt;cptable&lt;/code&gt; appears as &lt;code&gt;xstd&lt;/code&gt;) from 1 to see if I could get any number that vaguely resembled the ones that appeared in the table.&lt;/p&gt;
&lt;p&gt;Now all is clear. I think. Let me try to explain in my own words:&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; rule refers to picking the “best” (defined as the one with lowest cross-validated error &lt;code&gt;xerror&lt;/code&gt;) or the smallest (least splits) within one standard error &lt;code&gt;xstd&lt;/code&gt; of the best tree.&lt;/p&gt;
&lt;p&gt;Let’s go back to the example I couldn’t understand in &lt;a href=&#34;https://acastillogill.com/note/surrogate-who/&#34;&gt;this entry&lt;/a&gt; and try to figure out why they picked the tree they do.&lt;/p&gt;
&lt;p&gt;Here’s the table again:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/note/Mon-12-11-2018_files/cptable.png&#34; alt=&#34;CP table on page 16 from the Rpart documentation.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;CP table on page 16 from the Rpart documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The “best” tree appears in row 11 since it has the smallest &lt;code&gt;xerror&lt;/code&gt;, 0.36667.
Let’s look at which trees are within one standard error &lt;code&gt;xstd&lt;/code&gt; of the best tree.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(0.36667+0.03694=0.4036\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Which smaller tree has &lt;code&gt;xerror&lt;/code&gt; less than 0.4036? The tree on row 9 with &lt;code&gt;xerror&lt;/code&gt;= 0.3944.&lt;/p&gt;
&lt;p&gt;Aha! Mystery solved on why the tree with 9 splits was the best.&lt;/p&gt;
&lt;p&gt;Now, regarding the &lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt;, on the &lt;a href=&#34;https://stackoverflow.com/questions/29197213/what-is-the-difference-between-rel-error-and-x-error-in-a-rpart-decision-tree&#34;&gt;same thread&lt;/a&gt; where I found that rule, I found another comment saying that &lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; should not be used for pruning and cited this rule:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(xerror &amp;lt; min(xerror) + xstd\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Which is the &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; which apparently is much quoted and standard. For now I will stick to that one.&lt;/p&gt;
&lt;p&gt;As a final quick note on the &lt;code&gt;rpart&lt;/code&gt; documentation, I think it included a lot of terms that were not all defined within and expected some minimum statistical understanding from the reader. Just saying.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-make-a-laundry-list-of-the-algorithms-hyperparameters.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Make a laundry list of the algorithms hyperparameters.&lt;/h2&gt;
&lt;p&gt;So, as explained on the helpful DataFramed course I took on Machine Learning with Trees, hyperparameters are like knobs to tune the tree. That explanation intuitive enough for me to recall and understand what they are so I’ll leave at that for today.&lt;/p&gt;
&lt;p&gt;Now, with &lt;code&gt;?rpart.control&lt;/code&gt;, let’s check what they are. Since the dataset I’ll use to try out this algorithm does not have missing values, I will not include surrogate-related hyperparameters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;minsplit&lt;/code&gt;: “The minimum number of observations that must exist in a node in order for a split to be attempted.”&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minbucket&lt;/code&gt;: &amp;quot;The minimum number of observations in any terminal &lt;leaf&gt; node. If only one of minbucket or minsplit is specified, the code either sets &lt;code&gt;minsplit&lt;/code&gt; to &lt;code&gt;minbucket&lt;/code&gt;*3 or &lt;code&gt;minbucket&lt;/code&gt; to `minsplit/3, as appropriate.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cp&lt;/code&gt;: Complexity parameter. “Any split that does not decrease the overall lack of fit by a factor of &lt;code&gt;cp&lt;/code&gt; is not attempted. In anova, the overall R-squared must increase by &lt;code&gt;cp&lt;/code&gt; at each step. Essentially, the user informs the program that any split which does not improve the fit by &lt;code&gt;cp&lt;/code&gt; will likely be pruned off by cross-validation.” Interesting. Keen to see this in practice.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxcompete&lt;/code&gt;: The number of competing splits in the output, this serves to know what variable came in second, third, for the chosen split.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;xval&lt;/code&gt;: Number of cross-validations.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxdepth&lt;/code&gt;: The maximum depth of the final tree with the root node being 0 and max=30. This means… 29 splits, right? I think so since there is always 1+&lt;code&gt;nsplits&lt;/code&gt; nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OK. So the goals for the day have been reached. Tomorrow I will do some variable bining and explain why, after that I think I am ready to apply the final iteration of the &lt;code&gt;rpart&lt;/code&gt; algorithm, interpret the results, and publish the post.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Surrogate who?</title>
      <link>/note/surrogate-who/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/surrogate-who/</guid>
      <description>


&lt;p&gt;I hope the authors of the &lt;code&gt;Rpart&lt;/code&gt; documentation don’t take it personally but they mention surrogate variables starting on page 11 and they don’t properly define what surrogate variables mean until page 18. Maybe it’s just me.&lt;/p&gt;
&lt;p&gt;Anyway! So here is another response to a previous question: what is a surrogate variable?&lt;/p&gt;
&lt;p&gt;So the &lt;code&gt;Rpart&lt;/code&gt; algorithm deals with missing data. The way it does this is when it’s doing its thing and determining the next variable and split point and comes across an observation that does not have a that variable, it figures out which variables can act as a replacement for that variable. Surrogate variable mystery solved. N&lt;/p&gt;
&lt;p&gt;Now I’m having a bit of trouble figuring out if all the rules I’ve read for choosing the best tree are the same. In the DataCamp course we pick the tree that minimises &lt;code&gt;xerror&lt;/code&gt;. Yesterday I posted this rule I found on Cross Validated:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the documentation this is a rule:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In my next post I’m going to get to the bottom of this. I’m particularly confused because if we want to minimise the &lt;code&gt;xerror&lt;/code&gt;, why does page 16 of the documentation show a cptable with 27 splits and says: we see that the best tree has 10 terminal nodes, 9 splits, based on cross-validation. It has &lt;code&gt;xerror&lt;/code&gt; 0.3944.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/Thurs-08-11-2018_files/cptable.png&#34; alt=&#34;CP table on page 16 from the Rpart documentation.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;CP table on page 16 from the Rpart documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Doesn’t the tree with 11 splits and 12 nodes have the first smallest error with 0.36667?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Choosing the best tree</title>
      <link>/note/choosing-the-best-tree/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/choosing-the-best-tree/</guid>
      <description>


&lt;p&gt;According to user Harold Ship in &lt;a href=&#34;https://stackoverflow.com/questions/29197213/what-is-the-difference-between-rel-error-and-x-error-in-a-rpart-decision-tree&#34;&gt;this post&lt;/a&gt;, we should pick the tree with that keeps this relationship but has the tallest (that’s what he means with the lowest level, since each row represents a tree with more splits):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding output tables</title>
      <link>/note/understanding-output-tables/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/understanding-output-tables/</guid>
      <description>


&lt;p&gt;I’ve been able to answer quite a few of the questions that I asked before. For example, I don’t have to remove outliers because the algorithm is robust to outliers. No centering and scaling needs to be done to the variables. I can leave factors as factors, but the issue with with a lot of levels is that the tree can get quite wide which reduces its interpretability, which is after all, one of the advantages of using binary trees.
I’ve also answered what constitutes an improvemment in the branch-splitting algorithm, which is finding a variable that can produce the most homogenous subgroups after a split.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rpart&lt;/code&gt; function has several hyperparameters I would like to really understand before I modify the variables.
Today I set out to understand these hyperparameters but instead got caught up understanding the, “five additional ingredients” that need be specified to “generalise”extend&amp;quot; the algorithm.
These are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Splitting criterion, in ANOVA, this is maximising the between-groups sum-of-squares in a simple analysis of variance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(SS_T-(SS_L+SS_R)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(SS_T\)&lt;/span&gt; is the sum of squares for the node; &lt;span class=&#34;math inline&#34;&gt;\(SS_L\)&lt;/span&gt; is the sum of squares for the left son; and &lt;span class=&#34;math inline&#34;&gt;\(SS_R\)&lt;/span&gt; is the sum of squares for the right son.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;A summary statistic or vector to describe a node. The first element is considered to be the fitted value. For ANOVA or regression, this the mean of the node.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Error of the node: Variance of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for ANOVA.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The prediction error for a new observation, assigned to the node (&lt;span class=&#34;math inline&#34;&gt;\(y_{new}-\bar{y}\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Any initalisation parameter.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I was also trying to understand the output of &lt;code&gt;printcp()&lt;/code&gt; which shows the complexity parameter in descending order.&lt;/p&gt;
&lt;p&gt;It shows the columns: &lt;code&gt;cp&lt;/code&gt;, &lt;code&gt;nsplit&lt;/code&gt;, &lt;code&gt;rel error&lt;/code&gt;, &lt;code&gt;Xerror&lt;/code&gt;, and &lt;code&gt;Xstd&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rel error&lt;/code&gt;: is defined as &lt;span class=&#34;math inline&#34;&gt;\(1-R^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Xerror&lt;/code&gt;: “related to the PRESS statistic”. What is the PRESS statistic?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Xstd&lt;/code&gt;: related to the cross validation error.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, when reading the &lt;code&gt;rpart&lt;/code&gt; documentation, the authors constantly refer to a surrogate split. Which I’m having a bit of trouble trying to understand.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memorising tip</title>
      <link>/note/memorising-tip/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/memorising-tip/</guid>
      <description>


&lt;p&gt;Today I went to a poetry competition and heard a useful tip for memorising a poem, or in my case, speeches. Sometimes when we can’t memorise certain part of a text, after trying many times, maybe whatever is written down there, should go on the final version. Memorising can be a tool for editing the final text. When you read the text aloud, it’s own cadence and rhythm will point out that that word shouldn’t be there.&lt;/p&gt;
&lt;p&gt;I’ve joined the local chapter of Toastmasters and this recently happened to me with a speech. There were two lines in the third paragraph that I just couldn’t remember. After trying to memorise them over and over, I realised that actually the bit I was struggling with could have been said in another way. In a way that was more memorable for the audience and that made more sense within the text. Changed it and voila! Same idea expressed differently and it was easy to memorise and it made a bigger impact.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pre-processing to what extent?</title>
      <link>/note/pre-processing-to-what-extent/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/pre-processing-to-what-extent/</guid>
      <description>


&lt;p&gt;The goal of today’s session was to learn how to preprocess the homes dataset I’ve been working with. The missing values have been filled and now I have a few questions about whether I should perform or not, additional pre-processing steps before I can implement the CART algorithm.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Should I remove highly correlated variables? I have three and I don’t know what to do with them?&lt;/li&gt;
&lt;li&gt;Should I remove levels within factor variables with few observations?&lt;/li&gt;
&lt;li&gt;Should I bin variables with lots of factors like neighboorhoods?&lt;/li&gt;
&lt;li&gt;Should I bin numeric variables that related to the same metric? (i.e. square feet)&lt;/li&gt;
&lt;li&gt;What about outliers?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So for now I’m reading the introduction to &lt;a href=&#34;https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf&#34;&gt;Recursive Partioning document that comes with the R Part package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am also trying to figure out what constitutes improvements in the branch-splitting algorithm to know why it stops when it does.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
