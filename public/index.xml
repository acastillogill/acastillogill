<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ángela Castillo-Gill on Ángela Castillo-Gill</title>
    <link>/</link>
    <description>Recent content in Ángela Castillo-Gill on Ángela Castillo-Gill</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ángela Castillo-Gill</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Why did error go up?</title>
      <link>/note/why-did-error-go-up/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/why-did-error-go-up/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Figure out why the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; went up when I chose an “improved” tree.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-figure-out-why-the-rmse-and-mse-went-up-when-i-chose-an-improved-tree.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Figure out why the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; went up when I chose an “improved” tree.&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the base model &lt;code&gt;homes_model&lt;/code&gt; is 46893.56 and the &lt;code&gt;mae&lt;/code&gt; is 31678.89.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the improved model &lt;code&gt;homes_model_opt&lt;/code&gt; is 49963.95 and the &lt;code&gt;mae&lt;/code&gt; is 33909.8.&lt;/p&gt;
&lt;p&gt;This shouldn’t be the case, or should it?&lt;/p&gt;
&lt;p&gt;Let’s think what an increase in these two types of performance metrics mean. In the &lt;code&gt;rmse&lt;/code&gt; case, yesterday we saw that this is a measure of how much the fit deviates from real values.
An increase of 3070.39 means that the pruned model is a worse fit. WHY? Shouldn’t a smaller tree prevent overfitting?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An objective measure</title>
      <link>/note/an-objective-measure/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/an-objective-measure/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Evaluate the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; in the base and improved tree.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-evaluate-the-rmse-and-mse-in-the-base-and-improved-tree.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Evaluate the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; in the base and improved tree.&lt;/h2&gt;
&lt;p&gt;Right. So we know from previous posts that we pick the smallest tree within one standard error of the lowest &lt;code&gt;xerror&lt;/code&gt;. Eggsellent. BUT. What can we use to objectively measure the difference between trees? We can use the error between a less pruned tree and the improved one.&lt;/p&gt;
&lt;p&gt;There are two measurements of error, the &lt;code&gt;rmse&lt;/code&gt; and the &lt;code&gt;mae&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The root mean square error (RMSE) or root mean standard deviation (RMSD) is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[RMSD =\sqrt {\frac {\sum _{i=1}^{n}({\hat {y}}_{i}-y_{i})^{2}}{n}}\]&lt;/span&gt;
Where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the sample size, and &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{i}\)&lt;/span&gt; are the predicted values for the dependent variable &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Without reading the definition, this looks like it it “punishing” the differences between the estimated values and actual values, then dividing it per observation and taking the square root so the units are the actual ones for the response variable.&lt;/p&gt;
&lt;p&gt;The other &lt;em&gt;performance metric&lt;/em&gt;, which is the actual name for these tree-measuring-metrics, is called the &lt;code&gt;MAE&lt;/code&gt;. Which I think stands for the mean absolute error is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[MAE ={\frac {\sum _{i=1}^{n}\left|y_{i}-\hat {y_i}\right|}{n}}\]&lt;/span&gt;
It seems like the difference here is that the &lt;code&gt;RMSE&lt;/code&gt; punishes differences while the &lt;code&gt;MAE&lt;/code&gt; doesn’t emphasise large differences as much.&lt;/p&gt;
&lt;p&gt;Now let’s calculate these performance metrics for the original tree and then the pruned tree.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:basic-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Tuesday-20-11-2018_files/figure-html/basic-model-1.png&#34; alt=&#34;A first model suggests 9 splits with 10 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A first model suggests 9 splits with 10 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the base model &lt;code&gt;homes_model&lt;/code&gt; is 4.68910^{4} and the &lt;code&gt;mae&lt;/code&gt; is 3.16810^{4}.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:improved-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Tuesday-20-11-2018_files/figure-html/improved-model-1.png&#34; alt=&#34;Improved model has 7 splits and 8 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Improved model has 7 splits and 8 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;rmse&lt;/code&gt; for the improved model &lt;code&gt;homes_model_opt&lt;/code&gt; is 4.99610^{4} and the &lt;code&gt;mae&lt;/code&gt; is 3.39110^{4}.&lt;/p&gt;
&lt;p&gt;Ugh oh. It has gone up. Something is wrong. Why?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The basics</title>
      <link>/note/the-basics/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/the-basics/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Go over the difference between standard deviation, variance, and standard error.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Evaluate the &lt;code&gt;RMSE&lt;/code&gt; and &lt;code&gt;MSE&lt;/code&gt; in the base and improved tree.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-go-over-the-difference-between-standard-deviation-variance-and-standard-error.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Go over the difference between standard deviation, variance, and standard error.&lt;/h2&gt;
&lt;p&gt;So in a few machine learning algorithms, if not all of them, there are three terms that are contantly being used with “mean” and “median”: Standard deviation, variance, and standard error. I have probably studied these three terms and written their formulas too many times to mention here and you know what? If you asked me right now to explain the difference with every day examples, I don’t think I could. Over time they have become a mush and I realise the reason they don’t stick is because they are something I haven’t associated with something that makes sense to me.&lt;/p&gt;
&lt;p&gt;So today I will define these world-renowned measures of dispersion today and try to come up with examples from my every day life.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sample variance:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s^2 = \frac{1}{N-1} \sum_{i=1}^N (x_i - \overline{x})^2\]&lt;/span&gt;
Where, &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is the sample size; &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is the observation or piece of data, and &lt;span class=&#34;math inline&#34;&gt;\(\overline{x}\)&lt;/span&gt; is the data set mean.&lt;/p&gt;
&lt;p&gt;The differences between each point and the mean are squared to avoid negative differences cancelling positive ones. The variance units are the mean units squared.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Today I went for my grocery shop so let’s work from there. Let’s say I add lemons (1.68), apples (1.9), grapes (1.4), bananas (.97), and pine nuts (5.4) to my receipt.&lt;/p&gt;
&lt;p&gt;Then I ask, I wonder what the average price of each ingredient was, so I add and divide to create a simple average.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grocery_bill&amp;lt;- c(1.68,1.9,1.4,0.97,5.4)
sum(grocery_bill)/length(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2.27, fabulous. Now, I want to see how much variation there is amongst each ingredient.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grocery_bill-mean(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.59 -0.37 -0.87 -1.30  3.13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems like the last two items, bananas and pine nuts varied quite a bit more from the mean. Let’s add the differences now because let’s say I want to show my husband how bigger the difference is when we add pine nuts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(grocery_bill-mean(grocery_bill))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They have cancelled out. I think this is what you do when you want the regression line to go through the origin.&lt;/p&gt;
&lt;p&gt;In order to take each difference without it cancelling out, we SQUARE. AHA. Ok. I think maybe this will help it stick.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum((grocery_bill-mean(grocery_bill))^2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12.7288&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, now we divide by the 5 items.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sum((grocery_bill-mean(grocery_bill))^2))/5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.54576&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.1822&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I also computed the variance with base R and they were different. Why? Because I forgot the &lt;span class=&#34;math inline&#34;&gt;\(N-1\)&lt;/span&gt; bit. Classic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sum((grocery_bill-mean(grocery_bill))^2))/4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.1822&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.1822&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now they are the same. But why do we substract &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt;. It seems the answer is because we want to have an unbiased estimator and it’s called the &lt;em&gt;Bessel’s correction&lt;/em&gt; (?????).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sample standard deviation:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (x_i -\overline{x})^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now, the sample standard deviation is just the square root of the variance. It has the same units as the mean. On our groceries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt((sum((grocery_bill-mean(grocery_bill))^2))/4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.783872&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(grocery_bill)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.783872&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is the same! Ok. Well done. So 1.78 Euros is how much each item of my grocery list on average deviates from the mean which was 2.27.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standard error:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma_{\bar {x}}\ \approx {\frac {s}{\sqrt {n}}}\]&lt;/span&gt;
So from what I can see it’s the sample standard deviation divided by the square root of the sample size. mmmm, but why?&lt;/p&gt;
&lt;p&gt;According to Wikipedia: &lt;em&gt;The standard error (SE) of a statistic (usually an estimate of a parameter) is the standard deviation of its sampling distribution…&lt;/em&gt;
mmmmm ok.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;or an estimate of that standard deviation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Looking at the formula, this latter definition makes more sense.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If the parameter or the statistic is the mean, it is called the standard error of the mean (SEM).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But actually, not. I don’t really get this, yet.&lt;/p&gt;
&lt;p&gt;Then it reads: &lt;em&gt;It can also be understood as the standard deviation of the error in the sample mean with respect to the true mean (or an estimate of that statistic).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I think I’m going to let this one sink for today because I gotta run.&lt;/p&gt;
&lt;p&gt;You know what, this was extremely basic but a helpful reminder I should do more often. Would be fun to compare the standard deviation between my grocery shop and my husband’s. I need a refresher like this with the median and distribution skewness.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Did the tree improve?</title>
      <link>/note/did-the-tree-improve/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/did-the-tree-improve/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Show if the variable change made the tree more interpretable.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Splitting data
# Randomly assign rows to ids (1/2/3 represents train/valid/test)
# This will generate a vector of ids of length equal to the number of rows
# The train/valid/test split will be approximately 70% / 15% / 15% 
set.seed(1)
assignment &amp;lt;- sample(1:3, size = nrow(homes),
                     prob = c(0.7,0.15,0.15),
                     replace = TRUE)

# Create a train, validation and tests from the original data frame 
homes_train &amp;lt;- homes[assignment == 1, ]    # subset the homes data frame to training indices only
homes_valid &amp;lt;- homes[assignment == 2, ]  # subset the homes data frame to validation indices only
homes_test &amp;lt;- homes[assignment == 3, ]   # subset the homes data frame to test indices only&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Train the model
homes_model &amp;lt;- rpart(formula = SalePrice ~ ., 
                     data = homes_train, 
                     method = &amp;quot;anova&amp;quot;)

# Plot the basic model
rpart.plot(x = homes_model, type = 5, extra = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:basic-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Fri-16-11-2018_files/figure-html/basic-model-1.png&#34; alt=&#34;A first model suggests 9 splits with 10 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A first model suggests 9 splits with 10 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now we are going to look at the CP table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot the &amp;quot;CP Table&amp;quot;
plotcp(homes_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/note/Fri-16-11-2018_files/figure-html/tuning-hyperparameters-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Print the &amp;quot;CP Table&amp;quot;
print(homes_model$cptable)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            CP nsplit rel error    xerror       xstd
## 1  0.44576120      0 1.0000000 1.0034376 0.09648934
## 2  0.11362733      1 0.5542388 0.5578944 0.05448931
## 3  0.07787835      2 0.4406115 0.4760270 0.05459581
## 4  0.03461959      3 0.3627331 0.4091012 0.03666288
## 5  0.02116148      4 0.3281135 0.3979878 0.04568692
## 6  0.01818931      5 0.3069520 0.4082587 0.04732241
## 7  0.01742778      6 0.2887627 0.3937271 0.04468678
## 8  0.01671704      7 0.2713350 0.3939984 0.04468230
## 9  0.01294838      8 0.2546179 0.3677683 0.04291999
## 10 0.01000000      9 0.2416695 0.3524860 0.04281097&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According the &lt;code&gt;cptable&lt;/code&gt;, the lowest &lt;code&gt;xerror&lt;/code&gt; is in row 10, to that we add the &lt;code&gt;xstd&lt;/code&gt; error and obtain: &lt;span class=&#34;math inline&#34;&gt;\(0.39529\)&lt;/span&gt;. We see that the smallest error with &lt;code&gt;xerror&lt;/code&gt; below that is the tree with 7 splits and 8 nodes. I will use that in the improved plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Retrieve optimal cp value based on cross-validated error
opt_index &amp;lt;- 7
cp_opt &amp;lt;- homes_model$cptable[opt_index, &amp;quot;CP&amp;quot;]

# Prune the model (to optimized cp value)
homes_model_opt &amp;lt;- prune(tree = homes_model, 
                         cp = cp_opt)
                          
# Plot the optimized model
 rpart.plot(x = homes_model_opt, type = 5, extra = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:improved-model&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/note/Fri-16-11-2018_files/figure-html/improved-model-1.png&#34; alt=&#34;Improved model has 7 splits and 8 nodes.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Improved model has 7 splits and 8 nodes.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Tomorrow, I will look to see if there are any objective measures of error, clue, there are! And apply them to compare both models.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Binning the neighborhood variable (for real now)</title>
      <link>/note/binning-the-neighborhood-variable-for-real-now/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/binning-the-neighborhood-variable-for-real-now/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create a new variable that captures what the variable is providing without so many levels.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-create-a-new-variable-that-captures-what-the-variable-is-providing-without-so-many-levels.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Create a new variable that captures what the variable is providing without so many levels.&lt;/h2&gt;
&lt;p&gt;As we saw yesterday from looking at the quantiles, we have 25 neighborhoods but very few houses are in the most expensive neighborhoods.&lt;/p&gt;
&lt;p&gt;I’m looking at the plot again and I realise there is something very odd with it. None of the homes costs more than 755,000 and yet the plot goes up to 30,000,000. I realised that I was adding the &lt;code&gt;SalePrice&lt;/code&gt; of individuals homes. Now here is another go with actual average &lt;code&gt;SalePrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Thurs-15-11-2018_files/Mean_sale_price.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Much better. Now we can see that &lt;code&gt;NoRidge&lt;/code&gt; has the highest average &lt;code&gt;SalePrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s look at this again in light of the quantiles,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; neigh_quant
# A tibble: 5 x 3
  names      x incomes      
  &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        
1 0%     34900 Lower        
2 25%   129975 Middle_Lower 
3 50%   163000 Lower        
4 75%   214000 Middle_Higher
5 100%  755000 Higher &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems like the top 8 neighborhoods would go into the &lt;code&gt;Higher&lt;/code&gt; bracket and none would go into the lowest.&lt;/p&gt;
&lt;p&gt;The way that I’m going to bin the neighborhoods is that I will create a variable called &lt;code&gt;Neighboord_type&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Houses that have neighborhoods with average &lt;code&gt;SalePrice&lt;/code&gt; above 200,000 will go into the level “Fancy”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Houses that have neighborhoods with average &lt;code&gt;SalePrice&lt;/code&gt; above 150,000 and below 200,000 will go into the level “Somewhat_fancy”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Houses that have neighborhoods with average &lt;code&gt;SalePrice&lt;/code&gt; above 100,000 and below 150,000 will go into the level “Not_fancy”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The rest will go into the “OK” level. Because it’s ok if you don’t live in a fancy neighborhood.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And this is what it looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Thurs-15-11-2018_files/New_var.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Job done I would say.&lt;/p&gt;
&lt;p&gt;Tomorrow I will do everything again with this new variable to see if the plot improves.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Binning the neighborhood variable</title>
      <link>/note/binning-the-neighborhood-variable/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/binning-the-neighborhood-variable/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Understand what information is the &lt;code&gt;neighboorhood&lt;/code&gt; variable providing&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a new variable that captures what the variable is providing without so many levels.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-understand-what-information-is-the-neighboorhood-variable-providing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Understand what information is the &lt;code&gt;neighboorhood&lt;/code&gt; variable providing&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(homes$Neighborhood)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shows that the variable has 25 levels. Let’s see the relationship between each level and the response variable &lt;code&gt;SalesPrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Plotting the &lt;code&gt;neighboorhood&lt;/code&gt; variable shows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Wed-14-11-2018_files/neigh_salesprice.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-create-a-new-variable-that-captures-what-the-variable-is-providing-without-so-many-levels.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Create a new variable that captures what the variable is providing without so many levels.&lt;/h2&gt;
&lt;p&gt;Let’s say we want to create a variable with four levels, these would be the quantile cuts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    0%    25%    50%    75%   100% 
 34900 129975 163000 214000 755000 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows for example that only very few neighborhoods will be in the last quantile (above &lt;code&gt;$755,000&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Tomorrow I will do the rest cause right now I gotta go.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Applying concepts learned to property prices</title>
      <link>/note/applying-concepts-learned-to-property-prices/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/applying-concepts-learned-to-property-prices/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Interpret the &lt;code&gt;cptable&lt;/code&gt; for the generic &lt;code&gt;homes_model&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Interpret the &lt;code&gt;rpart.plot&lt;/code&gt; associated to &lt;code&gt;homes_model&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bin the &lt;code&gt;neighborhood&lt;/code&gt; variable and explain why I’m doing that.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-interpret-the-cptable-for-the-generic-homes_model.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Interpret the &lt;code&gt;cptable&lt;/code&gt; for the generic &lt;code&gt;homes_model&lt;/code&gt;.&lt;/h2&gt;
&lt;p&gt;With the &lt;code&gt;homes&lt;/code&gt; data as is (just removing missing values), I fited a model to predict &lt;code&gt;SalesPrice&lt;/code&gt; using &lt;code&gt;rpart()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;homes_model &amp;lt;- rpart(formula = SalePrice ~ ., 
                     data = homes_train, 
                     method = &amp;quot;anova&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at the &lt;code&gt;cptable&lt;/code&gt; with &lt;code&gt;homes_model$cptable&lt;/code&gt;, I’ll apply the &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; rule I explained yesterday:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Tues-13-11-2018_files/cptable_rawhomes.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;First, we can see that the smallest cross-validation &lt;code&gt;xerror&lt;/code&gt; appears on row 11. Now let’s add 1 standard error &lt;code&gt;xstd&lt;/code&gt;: &lt;span class=&#34;math inline&#34;&gt;\(0.3074050+0.03541012=0.3428151\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The smallest tree with &lt;code&gt;xerror&lt;/code&gt; less than &lt;span class=&#34;math inline&#34;&gt;\(0.3428151\)&lt;/span&gt; is the tree appearing on row 8 with 8 splits and 9 nodes.&lt;/p&gt;
&lt;p&gt;Now, I look at the &lt;code&gt;plotcp(homes_model)&lt;/code&gt;, I’m confused to whether size of the tree refers to nodes or splits:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Tues-13-11-2018_files/cpplot_rawhomes.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I think it refers to nodes because the &lt;code&gt;xerror&lt;/code&gt; for the tree with 9 nodes appears on the dotted line. A dotted line that intersects the 9-tree node must mean it’s the chosen one, right? :laughing:&lt;/p&gt;
&lt;p&gt;Now, let’s run the model again, but specifying the best model, with 8 splits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Hard code best tree based on above explained analysis
opt_index &amp;lt;- 8
#Retrieve cp_opt
cp_opt &amp;lt;- homes_model$cptable[opt_index, &amp;quot;CP&amp;quot;]
# Prune the model (to optimized cp value)
homes_model_opt &amp;lt;- prune(tree = homes_model, 
                         cp = cp_opt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I suppose hard coding the number 8 instead of writing the code to pick the best tree isn’t too elegant, but bear with me. Writing clean code is not the priority right now. :hankey:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-interpret-the-rpart.plot-associated-to-homes_model.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Interpret the &lt;code&gt;rpart.plot&lt;/code&gt; associated to &lt;code&gt;homes_model&lt;/code&gt;.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rpart.plot(x = homes_model_opt, type = 5, extra = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That code produces this plot:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/note/Tues-13-11-2018_files/rpartplot_rawhomes.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It has 8 splits and 9 nodes and we asked it to. Inside each terminal node is the number of observations which add up to 1025. Each split specifies the criteria for the observation being classified either into the left or right son.&lt;/p&gt;
&lt;p&gt;If we go back and look at the numeric variables that had the highest correlation with &lt;code&gt;SalesPrice&lt;/code&gt;, &lt;code&gt;OverallQual&lt;/code&gt; was leading followed by &lt;code&gt;GrLivArea&lt;/code&gt;. In the tree we can see that these variables appear further below &lt;code&gt;X1stFlrSF&lt;/code&gt; and &lt;code&gt;GarageArea&lt;/code&gt; appear later down.&lt;/p&gt;
&lt;p&gt;The plot shows the &lt;code&gt;neighborhood&lt;/code&gt; variable twice and in the second level. So it’s an important variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-3-bin-the-neighborhood-variable-and-explain-why-im-doing-that.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 3: Bin the &lt;code&gt;neighborhood&lt;/code&gt; variable and explain why I’m doing that.&lt;/h2&gt;
&lt;p&gt;So today I don’t think I’ll be able to the binning since my alloted time for this is almost up. But I will explain the why since it appears clearly on the graph.&lt;/p&gt;
&lt;p&gt;One of the advantages of regression trees is that they area easy to understand and visualise. Because the &lt;code&gt;neighborhood&lt;/code&gt; variable has so many levels, it is actually going against one of the reasons I picked it. The whole neighborhood variable is confusing. Explaining the key differences amongst neighborhoods is not straightforward using just the plot. So I’m going to explore what the relationship between those neighborhoods and price is tomorrow and see if I can create another variable that better reflects that relationship. Exciting! :sparkles:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hyperparameter laundry list</title>
      <link>/note/hyperparameter-laundry-list/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/hyperparameter-laundry-list/</guid>
      <description>


&lt;div id=&#34;goals-for-todays-session-are&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goal’s for today’s session are:&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Get clarity on how to pick the best tree.&lt;/li&gt;
&lt;li&gt;Make a laundry list of the algorithms hyperparameters.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;goal-1-get-clarity-on-how-to-pick-the-best-tree.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 1: Get clarity on how to pick the best tree.&lt;/h2&gt;
&lt;p&gt;So far, my confusion stems from the &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; (“one standard error” rule) vs. the &lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt; rule.&lt;/p&gt;
&lt;p&gt;These two threads have helped me understand WHY they are the same:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/138569/why-is-lambda-within-one-standard-error-from-the-minimum-is-a-recommended-valu&#34;&gt;What’s the deal with this whole 1-SE rule.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/13471/how-to-choose-the-number-of-splits-in-rpart&#34;&gt;Applying the 1-SE rule.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So first of all, I didn’t even understand &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; when I read it in the Rpart documentation. What does it mean? I kept searching substracting &lt;span class=&#34;math inline&#34;&gt;\(SE\)&lt;/span&gt; (which in the &lt;code&gt;cptable&lt;/code&gt; appears as &lt;code&gt;xstd&lt;/code&gt;) from 1 to see if I could get any number that vaguely resembled the ones that appeared in the table.&lt;/p&gt;
&lt;p&gt;Now all is clear. I think. Let me try to explain in my own words:&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; rule refers to picking the “best” (defined as the one with lowest cross-validated error &lt;code&gt;xerror&lt;/code&gt;) or the smallest (least splits) within one standard error &lt;code&gt;xstd&lt;/code&gt; of the best tree.&lt;/p&gt;
&lt;p&gt;Let’s go back to the example I couldn’t understand in &lt;a href=&#34;https://acastillogill.com/note/surrogate-who/&#34;&gt;this entry&lt;/a&gt; and try to figure out why they picked the tree they do.&lt;/p&gt;
&lt;p&gt;Here’s the table again:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/note/Mon-12-11-2018_files/cptable.png&#34; alt=&#34;CP table on page 16 from the Rpart documentation.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;CP table on page 16 from the Rpart documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The “best” tree appears in row 11 since it has the smallest &lt;code&gt;xerror&lt;/code&gt;, 0.36667.
Let’s look at which trees are within one standard error &lt;code&gt;xstd&lt;/code&gt; of the best tree.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(0.36667+0.03694=0.4036\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Which smaller tree has &lt;code&gt;xerror&lt;/code&gt; less than 0.4036? The tree on row 9 with &lt;code&gt;xerror&lt;/code&gt;= 0.3944.&lt;/p&gt;
&lt;p&gt;Aha! Mystery solved on why the tree with 9 splits was the best.&lt;/p&gt;
&lt;p&gt;Now, regarding the &lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt;, on the &lt;a href=&#34;https://stackoverflow.com/questions/29197213/what-is-the-difference-between-rel-error-and-x-error-in-a-rpart-decision-tree&#34;&gt;same thread&lt;/a&gt; where I found that rule, I found another comment saying that &lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; should not be used for pruning and cited this rule:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(xerror &amp;lt; min(xerror) + xstd\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Which is the &lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt; which apparently is much quoted and standard. For now I will stick to that one.&lt;/p&gt;
&lt;p&gt;As a final quick note on the &lt;code&gt;rpart&lt;/code&gt; documentation, I think it included a lot of terms that were not all defined within and expected some minimum statistical understanding from the reader. Just saying.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-2-make-a-laundry-list-of-the-algorithms-hyperparameters.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal 2: Make a laundry list of the algorithms hyperparameters.&lt;/h2&gt;
&lt;p&gt;So, as explained on the helpful DataFramed course I took on Machine Learning with Trees, hyperparameters are like knobs to tune the tree. That explanation intuitive enough for me to recall and understand what they are so I’ll leave at that for today.&lt;/p&gt;
&lt;p&gt;Now, with &lt;code&gt;?rpart.control&lt;/code&gt;, let’s check what they are. Since the dataset I’ll use to try out this algorithm does not have missing values, I will not include surrogate-related hyperparameters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;minsplit&lt;/code&gt;: “The minimum number of observations that must exist in a node in order for a split to be attempted.”&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minbucket&lt;/code&gt;: &amp;quot;The minimum number of observations in any terminal &lt;leaf&gt; node. If only one of minbucket or minsplit is specified, the code either sets &lt;code&gt;minsplit&lt;/code&gt; to &lt;code&gt;minbucket&lt;/code&gt;*3 or &lt;code&gt;minbucket&lt;/code&gt; to `minsplit/3, as appropriate.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cp&lt;/code&gt;: Complexity parameter. “Any split that does not decrease the overall lack of fit by a factor of &lt;code&gt;cp&lt;/code&gt; is not attempted. In anova, the overall R-squared must increase by &lt;code&gt;cp&lt;/code&gt; at each step. Essentially, the user informs the program that any split which does not improve the fit by &lt;code&gt;cp&lt;/code&gt; will likely be pruned off by cross-validation.” Interesting. Keen to see this in practice.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxcompete&lt;/code&gt;: The number of competing splits in the output, this serves to know what variable came in second, third, for the chosen split.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;xval&lt;/code&gt;: Number of cross-validations.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxdepth&lt;/code&gt;: The maximum depth of the final tree with the root node being 0 and max=30. This means… 29 splits, right? I think so since there is always 1+&lt;code&gt;nsplits&lt;/code&gt; nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OK. So the goals for the day have been reached. Tomorrow I will do some variable bining and explain why, after that I think I am ready to apply the final iteration of the &lt;code&gt;rpart&lt;/code&gt; algorithm, interpret the results, and publish the post.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Surrogate who?</title>
      <link>/note/surrogate-who/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/surrogate-who/</guid>
      <description>


&lt;p&gt;I hope the authors of the &lt;code&gt;Rpart&lt;/code&gt; documentation don’t take it personally but they mention surrogate variables starting on page 11 and they don’t properly define what surrogate variables mean until page 18. Maybe it’s just me.&lt;/p&gt;
&lt;p&gt;Anyway! So here is another response to a previous question: what is a surrogate variable?&lt;/p&gt;
&lt;p&gt;So the &lt;code&gt;Rpart&lt;/code&gt; algorithm deals with missing data. The way it does this is when it’s doing its thing and determining the next variable and split point and comes across an observation that does not have a that variable, it figures out which variables can act as a replacement for that variable. Surrogate variable mystery solved. N&lt;/p&gt;
&lt;p&gt;Now I’m having a bit of trouble figuring out if all the rules I’ve read for choosing the best tree are the same. In the DataCamp course we pick the tree that minimises &lt;code&gt;xerror&lt;/code&gt;. Yesterday I posted this rule I found on Cross Validated:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the documentation this is a rule:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(1-SE\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In my next post I’m going to get to the bottom of this. I’m particularly confused because if we want to minimise the &lt;code&gt;xerror&lt;/code&gt;, why does page 16 of the documentation show a cptable with 27 splits and says: we see that the best tree has 10 terminal nodes, 9 splits, based on cross-validation. It has &lt;code&gt;xerror&lt;/code&gt; 0.3944.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/Thurs-08-11-2018_files/cptable.png&#34; alt=&#34;CP table on page 16 from the Rpart documentation.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;CP table on page 16 from the Rpart documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Doesn’t the tree with 11 splits and 12 nodes have the first smallest error with 0.36667?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Choosing the best tree</title>
      <link>/note/choosing-the-best-tree/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/choosing-the-best-tree/</guid>
      <description>


&lt;p&gt;According to user Harold Ship in &lt;a href=&#34;https://stackoverflow.com/questions/29197213/what-is-the-difference-between-rel-error-and-x-error-in-a-rpart-decision-tree&#34;&gt;this post&lt;/a&gt;, we should pick the tree with that keeps this relationship but has the tallest (that’s what he means with the lowest level, since each row represents a tree with more splits):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(rel\&amp;gt;error\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xstd\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(xerror\)&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding output tables</title>
      <link>/note/understanding-output-tables/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/understanding-output-tables/</guid>
      <description>


&lt;p&gt;I’ve been able to answer quite a few of the questions that I asked before. For example, I don’t have to remove outliers because the algorithm is robust to outliers. No centering and scaling needs to be done to the variables. I can leave factors as factors, but the issue with with a lot of levels is that the tree can get quite wide which reduces its interpretability, which is after all, one of the advantages of using binary trees.
I’ve also answered what constitutes an improvemment in the branch-splitting algorithm, which is finding a variable that can produce the most homogenous subgroups after a split.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rpart&lt;/code&gt; function has several hyperparameters I would like to really understand before I modify the variables.
Today I set out to understand these hyperparameters but instead got caught up understanding the, “five additional ingredients” that need be specified to “generalise”extend&amp;quot; the algorithm.
These are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Splitting criterion, in ANOVA, this is maximising the between-groups sum-of-squares in a simple analysis of variance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(SS_T-(SS_L+SS_R)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(SS_T\)&lt;/span&gt; is the sum of squares for the node; &lt;span class=&#34;math inline&#34;&gt;\(SS_L\)&lt;/span&gt; is the sum of squares for the left son; and &lt;span class=&#34;math inline&#34;&gt;\(SS_R\)&lt;/span&gt; is the sum of squares for the right son.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;A summary statistic or vector to describe a node. The first element is considered to be the fitted value. For ANOVA or regression, this the mean of the node.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Error of the node: Variance of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for ANOVA.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The prediction error for a new observation, assigned to the node (&lt;span class=&#34;math inline&#34;&gt;\(y_{new}-\bar{y}\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Any initalisation parameter.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I was also trying to understand the output of &lt;code&gt;printcp()&lt;/code&gt; which shows the complexity parameter in descending order.&lt;/p&gt;
&lt;p&gt;It shows the columns: &lt;code&gt;cp&lt;/code&gt;, &lt;code&gt;nsplit&lt;/code&gt;, &lt;code&gt;rel error&lt;/code&gt;, &lt;code&gt;Xerror&lt;/code&gt;, and &lt;code&gt;Xstd&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rel error&lt;/code&gt;: is defined as &lt;span class=&#34;math inline&#34;&gt;\(1-R^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Xerror&lt;/code&gt;: “related to the PRESS statistic”. What is the PRESS statistic?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Xstd&lt;/code&gt;: related to the cross validation error.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, when reading the &lt;code&gt;rpart&lt;/code&gt; documentation, the authors constantly refer to a surrogate split. Which I’m having a bit of trouble trying to understand.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memorising tip</title>
      <link>/note/memorising-tip/</link>
      <pubDate>Sun, 04 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/memorising-tip/</guid>
      <description>


&lt;p&gt;Today I went to a poetry competition and heard a useful tip for memorising a poem, or in my case, speeches. Sometimes when we can’t memorise certain part of a text, after trying many times, maybe whatever is written down there, should go on the final version. Memorising can be a tool for editing the final text. When you read the text aloud, it’s own cadence and rhythm will point out that that word shouldn’t be there.&lt;/p&gt;
&lt;p&gt;I’ve joined the local chapter of Toastmasters and this recently happened to me with a speech. There were two lines in the third paragraph that I just couldn’t remember. After trying to memorise them over and over, I realised that actually the bit I was struggling with could have been said in another way. In a way that was more memorable for the audience and that made more sense within the text. Changed it and voila! Same idea expressed differently and it was easy to memorise and it made a bigger impact.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pre-processing to what extent?</title>
      <link>/note/pre-processing-to-what-extent/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/pre-processing-to-what-extent/</guid>
      <description>


&lt;p&gt;The goal of today’s session was to learn how to preprocess the homes dataset I’ve been working with. The missing values have been filled and now I have a few questions about whether I should perform or not, additional pre-processing steps before I can implement the CART algorithm.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Should I remove highly correlated variables? I have three and I don’t know what to do with them?&lt;/li&gt;
&lt;li&gt;Should I remove levels within factor variables with few observations?&lt;/li&gt;
&lt;li&gt;Should I bin variables with lots of factors like neighboorhoods?&lt;/li&gt;
&lt;li&gt;Should I bin numeric variables that related to the same metric? (i.e. square feet)&lt;/li&gt;
&lt;li&gt;What about outliers?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So for now I’m reading the introduction to &lt;a href=&#34;https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf&#34;&gt;Recursive Partioning document that comes with the R Part package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am also trying to figure out what constitutes improvements in the branch-splitting algorithm to know why it stops when it does.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting property prices</title>
      <link>/post/2018-08-09-predicting-property-prices/predicting-property-prices/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-08-09-predicting-property-prices/predicting-property-prices/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#purpose-of-this-post&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Purpose of this post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; The data&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#missing-values&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1&lt;/span&gt; Missing values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variable-creation&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2&lt;/span&gt; Variable creation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3&lt;/span&gt; Correlation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#classification-and-regression-trees-cart-time&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Classification and Regression Trees (CART) time&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#splitting-the-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.1&lt;/span&gt; Splitting the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#training-the-model&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.2&lt;/span&gt; Training the model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#revising-variable-importance&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.3&lt;/span&gt; Revising variable importance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluating-the-model&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.4&lt;/span&gt; Evaluating the model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tuning-hyperparameters&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.5&lt;/span&gt; Tuning hyperparameters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#checking-the-error-on-the-optimised-model&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.6&lt;/span&gt; Checking the error on the optimised model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grid-search-for-best-hyperparameters&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.7&lt;/span&gt; Grid search for best hyperparameters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#techniques-used&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;5&lt;/span&gt; Techniques used&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#questions-from-this-analysis&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;6&lt;/span&gt; Questions from this analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Summary&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;To see the code used in this post, visit my &lt;a href=&#34;https://www.kaggle.com/adcastillogill/exploring-kiva-loans&#34;&gt;kernel on kaggle in R Markdown format&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;purpose-of-this-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Purpose of this post&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; The data&lt;/h1&gt;
&lt;p&gt;The dataset &lt;a href=&#34;https://www.kaggle.com/c/house-prices-advanced-regression-techniques&#34;&gt;House Prices: Advanced Regression Techniques&lt;/a&gt; was downloaded from Kaggle and put together by &lt;a href=&#34;https://ww2.amstat.org/publications/jse/v19n3/decock.pdf&#34;&gt;Dean De Cock.&lt;/a&gt; It has 79 explanatory variables describing 1,460 homes in Ames, Iowa. The codebook for all the variables can be &lt;a href=&#34;https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data&#34;&gt;found here.&lt;/a&gt; As I go along, I’ll explain the most relevant ones.&lt;/p&gt;
&lt;p&gt;First we will see how many numerical vs. categorical variables there are.&lt;/p&gt;
&lt;p&gt;Our dataset has 38 numeric and 43 character variables. Next, since we are interested in estimating sales prices &lt;code&gt;SalePrice&lt;/code&gt;, we will recode character variables and see the most strongly correlated variables. There are 43 character variables available. I want to recode them where there is ordinality and where there isn’t dummify them.&lt;/p&gt;
&lt;p&gt;There are two numerical variables that are actually date related: &lt;code&gt;YearBuilt&lt;/code&gt; and &lt;code&gt;YearRemodAdd&lt;/code&gt; (remodelled date). It makes more sense to make two new variables that relate the build and remodelled dates with the present. In other words, I will create the years since built and years since remodelled date variables, this will help interpret the results better.&lt;/p&gt;
&lt;div id=&#34;missing-values&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Missing values&lt;/h2&gt;
&lt;p&gt;As it more common than not, the dataset contains missing values. Missing values need to be dealt with because regression (and other models) requires complete observations.&lt;/p&gt;
&lt;p&gt;Dealing with missing data depends on &lt;em&gt;why the data are missing&lt;/em&gt;. &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/missing.pdf&#34;&gt;This article&lt;/a&gt; explains four reasons why data could be missing. When the data are missing at random (MAR) or completely at random (MCAR), observations with missing values can be removed without introducing bias into the model.&lt;/p&gt;
&lt;p&gt;Sometimes, however, if the dataset is not too big and we don’t want to lose observations, or even if it is big, yet we still don’t want to remove observations, we can impute data. Imputing means replacing missing values by doing some educated guesses. &lt;a href=&#34;https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4&#34;&gt;This article&lt;/a&gt; summarises how to impute data depending on why it is missing.&lt;/p&gt;
&lt;p&gt;If the data are not missing at random, then the imputation mechanism has to modelled.&lt;/p&gt;
&lt;p&gt;Let’s look at which variables are missing:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:missigness-table&#34;&gt;Table 3.1: &lt;/span&gt;Variables with missing values in descending order
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Variable
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Number of NAs
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
PoolQC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1453
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MiscFeature
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1406
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Alley
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1369
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Fence
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1179
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FireplaceQu
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
690
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LotFrontage
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
259
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageType
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageYrBlt
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageFinish
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageQual
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageCond
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtExposure
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtFinType2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtQual
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtCond
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtFinType1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MasVnrType
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MasVnrArea
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Electrical
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;19 variables have missing values. Based on the codebook, the reason why so many houses have &lt;code&gt;PoolQC&lt;/code&gt; missing is because &lt;code&gt;NA&lt;/code&gt;, means there is no pool. Since this variable is ordinal, I can revalue it to make it numerical and &lt;code&gt;0&lt;/code&gt; will mean the property has no pool. &lt;code&gt;MiscFeature&lt;/code&gt;, &lt;code&gt;Alley&lt;/code&gt;, &lt;code&gt;Fence&lt;/code&gt;, and &lt;code&gt;FireplaceQu&lt;/code&gt; are missing because of similar reasons. We don’t know why &lt;code&gt;LotFrontage&lt;/code&gt; is missing but we will impute as the median for properties in the same neighborhood. &lt;a href=&#34;https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda/code&#34;&gt;Erik Bruin’s kernel on Kaggle&lt;/a&gt; with this dataset, was a great guideline for what to do in each missing value case.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variable-creation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Variable creation&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/understanding-neighborhood-var-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Correlation&lt;/h2&gt;
&lt;p&gt;Correlation, &lt;span class=&#34;math inline&#34;&gt;\(Cor(X,Y)\)&lt;/span&gt;, measures the strength of the linear relationship between two variables &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The correlation between &lt;code&gt;SalePrice&lt;/code&gt; and another variable, let’s say, &lt;code&gt;OverallQual&lt;/code&gt;, is the covariance of the separately normalised data between the two variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov(scale(homes$SalePrice), scale(homes$OverallQual))
          [,1]
[1,] 0.7909816&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since covariance units are &lt;code&gt;OverallQual&lt;/code&gt; * &lt;code&gt;SalePrice&lt;/code&gt;, calculating the correlation is instead more helpful since it is unit free.&lt;/p&gt;
&lt;p&gt;If we created a model with only variable as the predictor of &lt;code&gt;SalesPrice&lt;/code&gt;, let’s say, &lt;code&gt;KitchenQual&lt;/code&gt; and normalised the data, the regression slope would be the correlation between the two variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;norm_fit &amp;lt;- lm(scale(SalePrice) ~ scale(KitchenQual), data = homes)
round(coefficients(norm_fit), digits = 2)
       (Intercept) scale(KitchenQual) 
              0.00               0.66 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the correlation matrix for variables that have a relationship stronger than 0.5 with &lt;code&gt;SalePrice&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/correlation-matrix-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are 17 variables that have a correlation stronger than 0.5. They are arranged in descending order. It is interesting to note the high correlation that exists amongst variables. The correlation plot highlights some obvious ones, &lt;code&gt;GarageArea&lt;/code&gt; and &lt;code&gt;GarageCars&lt;/code&gt;. Makes sense, a bigger garage can hold more cars. &lt;code&gt;X1stFlrSF&lt;/code&gt; and &lt;code&gt;TotalBsmtSF&lt;/code&gt;, the total area of the first floor and basement, this also seems reasonable since basements are underneath the same floor and would tend to have a similar area. &lt;code&gt;TotRmsAbvGrd&lt;/code&gt; and &lt;code&gt;GrLivArea&lt;/code&gt;, the total number of rooms and area above ground, again ok, more rooms would be linked to a bigger living area. Finally, &lt;code&gt;YearsSinceBuilt&lt;/code&gt; and &lt;code&gt;YearsSinceGarageBuilt&lt;/code&gt; since garages are usually built at the same time as the house.&lt;/p&gt;
&lt;p&gt;Here is the codebook for all the variables featured in the correlation matrix in case they come up later and we need to interpret what they mean.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Positive correlation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;OverallQual&lt;/code&gt;: Rates the overall material and finish of the house&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GrLivArea&lt;/code&gt;: Above grade (ground) living area square feet.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ExterQual&lt;/code&gt;: Exterior quality&lt;/li&gt;
&lt;li&gt;&lt;code&gt;KitchenQual&lt;/code&gt;: Kitchen quality&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GarageCars&lt;/code&gt;: Size of garage in car capacity&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GarageArea&lt;/code&gt;: Size of garage in square feet&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TotalBsmtSF&lt;/code&gt;: Total square feet of basement area&lt;/li&gt;
&lt;li&gt;&lt;code&gt;X1stFlrSF&lt;/code&gt;: First floor square feet&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BsmtQual&lt;/code&gt;: Height of basement&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FullBath&lt;/code&gt;: Full bathrooms above grade&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GarageFinish&lt;/code&gt;: Interior finish of the garage&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TotRmsAbvGrd&lt;/code&gt;: Total rooms above grade (does not include bathrooms)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FireplaceQu&lt;/code&gt;: Fireplace quality&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Negative correlation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;YearsSinceRemod&lt;/code&gt;: Years since remodel date (same as construction date if no remodelling or additions)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;YearsSinceGarageBuilt&lt;/code&gt;: Years since the garage was built&lt;/li&gt;
&lt;li&gt;&lt;code&gt;YearsSinceBuilt&lt;/code&gt;: Years since construction date&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;classification-and-regression-trees-cart-time&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Classification and Regression Trees (CART) time&lt;/h1&gt;
&lt;p&gt;In this post I am using the recursing and partitioning (RPART) algorithm also known as classification and regression trees (CART). It will be implemented with the &lt;code&gt;rpart&lt;/code&gt; package in R.&lt;/p&gt;
&lt;p&gt;Rpart, builds a model in two stages:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First stage&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;A single variable is identified which can best split the data into two groups. The data is then separated intwo two groups and the whole process is repeated &lt;em&gt;recursively&lt;/em&gt; or indefinitely until the sub groups reach a minimum size, or until no further improvements can be made.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To be defined later&lt;/strong&gt;
- What constitutes as the variable that BEST splits the data?&lt;/p&gt;
&lt;p&gt;When the split is made, similarity amongst the observations can more or less homogenous. This homogeneity is also called purity and it can be measured. The impurity measure of a node specifies how mixed the resulting subset is.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What are the further improvements that the algorithm can make?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are further splits that reduce the homogeneity of the subgroups.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Second stage&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;The tree is trimmed back or prunned using cross-validation.&lt;/p&gt;
&lt;div id=&#34;splitting-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; Splitting the data&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;training-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; Training the model&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;revising-variable-importance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3&lt;/span&gt; Revising variable importance&lt;/h2&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:variable-importance-table&#34;&gt;Table 4.1: &lt;/span&gt;Top 30 variables in order of importance
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Variable
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Percentage
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
OverallQual
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23.2881205
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtQual
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.3219127
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TotalBsmtSF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.2963511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageCars
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.9148899
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GarageArea
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.3353758
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Neighborhood_type
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.5795851
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
KitchenQual
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.3419024
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GrLivArea
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.9671386
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X1stFlrSF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.9252303
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FullBath
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.7461030
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
YearsSinceBuilt
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.7244438
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
YearsSinceGarageBuilt
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.0305361
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Foundation
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.6912965
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TotRmsAbvGrd
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.0111251
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MSSubClass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.1734153
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtFinSF1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0429523
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtUnfSF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8111851
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X2ndFlrSF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7053916
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
HouseStyle
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6331315
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LotArea
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4572123
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LotFrontage
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3740828
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MSZoning
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1799967
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BedroomAbvGr
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1711556
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtCond
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0714405
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtExposure
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0714405
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BsmtFinType1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0714405
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Id
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0315722
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
RoofStyle
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0315722
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluating-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4&lt;/span&gt; Evaluating the model&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;[1] 46893.56
[1] 31678.89&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tuning-hyperparameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5&lt;/span&gt; Tuning hyperparameters&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/tuning-hyperparameters-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           CP nsplit rel error    xerror       xstd
1  0.44576120      0 1.0000000 1.0034376 0.09648934
2  0.11362733      1 0.5542388 0.5578944 0.05448931
3  0.07787835      2 0.4406115 0.4760270 0.05459581
4  0.03461959      3 0.3627331 0.4091012 0.03666288
5  0.02116148      4 0.3281135 0.3979878 0.04568692
6  0.01818931      5 0.3069520 0.4082587 0.04732241
7  0.01742778      6 0.2887627 0.3937271 0.04468678
8  0.01671704      7 0.2713350 0.3939984 0.04468230
9  0.01294838      8 0.2546179 0.3677683 0.04291999
10 0.01000000      9 0.2416695 0.3524860 0.04281097&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/tuning-hyperparameters-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-the-error-on-the-optimised-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.6&lt;/span&gt; Checking the error on the optimised model&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;[1] 49963.95
[1] 33909.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;grid-search-for-best-hyperparameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.7&lt;/span&gt; Grid search for best hyperparameters&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;[1] 90  2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$minsplit
[1] 10 12 14 16 18 20

$minbucket
[1] 3 4 5 5 6 7

$cp
[1] 0.01

$maxcompete
[1] 4

$maxsurrogate
[1] 5

$usesurrogate
[1] 2

$surrogatestyle
[1] 0

$maxdepth
[1] 2

$xval
[1] 10
[1] 81900.42
$minsplit
[1] 10 12 14 16 18 20

$minbucket
[1] 3 4 5 5 6 7

$cp
[1] 0.01

$maxcompete
[1] 4

$maxsurrogate
[1] 5

$usesurrogate
[1] 2

$surrogatestyle
[1] 0

$maxdepth
[1] 2

$xval
[1] 10
[1] 58664.27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-09-predicting-property-prices/2018-08-09-predicting-property-prices_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;techniques-used&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; Techniques used&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;I&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;questions-from-this-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;6&lt;/span&gt; Questions from this analysis&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
